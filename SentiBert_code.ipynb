{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6dc2309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:41:55.845419Z",
     "iopub.status.busy": "2024-07-31T11:41:55.844935Z",
     "iopub.status.idle": "2024-07-31T11:42:02.785506Z",
     "shell.execute_reply": "2024-07-31T11:42:02.783548Z"
    },
    "papermill": {
     "duration": 6.96875,
     "end_time": "2024-07-31T11:42:02.788762",
     "exception": false,
     "start_time": "2024-07-31T11:41:55.820012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1002</td>\n",
       "      <td>1994</td>\n",
       "      <td>Using a neural net to instantiate a deformable...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002-using-a-neural-net-to-instantiate-a-defor...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>U sing a neural net to instantiate a\\ndeformab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003-plasticity-mediated-competitive-learning.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning\\n\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1004</td>\n",
       "      <td>1994</td>\n",
       "      <td>ICEG Morphology Classification using an Analog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004-iceg-morphology-classification-using-an-a...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>ICEG Morphology Classification using an\\nAnalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1005</td>\n",
       "      <td>1994</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma Using Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005-real-time-control-of-a-tokamak-plasma-usi...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1006</td>\n",
       "      <td>1994</td>\n",
       "      <td>Pulsestream Synapses with Non-Volatile Analogu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006-pulsestream-synapses-with-non-volatile-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1007</td>\n",
       "      <td>1994</td>\n",
       "      <td>Learning to Play the Game of Chess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1007-learning-to-play-the-game-of-chess.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Learning To Play the Game of Chess\\n\\nSebastia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1008</td>\n",
       "      <td>1994</td>\n",
       "      <td>Multidimensional Scaling and Data Clustering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008-multidimensional-scaling-and-data-cluster...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Multidimensional Scaling and Data Clustering\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1009</td>\n",
       "      <td>1994</td>\n",
       "      <td>An experimental comparison of recurrent neural...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009-an-experimental-comparison-of-recurrent-n...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>An experimental comparison\\nof recurrent neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101</td>\n",
       "      <td>1988</td>\n",
       "      <td>Training Multilayer Perceptrons with the Exten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101-training-multilayer-perceptrons-with-the-e...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>133\\n\\nTRAINING MULTILAYER PERCEPTRONS WITH TH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1010</td>\n",
       "      <td>1994</td>\n",
       "      <td>Interference in Learning Internal Models of In...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010-interference-in-learning-internal-models-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Interference in Learning Internal\\nModels of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1011</td>\n",
       "      <td>1994</td>\n",
       "      <td>Active Learning with Statistical Models</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1011-active-learning-with-statistical-models.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Active Learning with Statistical Models\\n\\nDav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1012</td>\n",
       "      <td>1994</td>\n",
       "      <td>A Rapid Graph-based Method for Arbitrary Trans...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012-a-rapid-graph-based-method-for-arbitrary-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Rapid Graph-based Method for\\nArbitrary Tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1013</td>\n",
       "      <td>1994</td>\n",
       "      <td>Ocular Dominance and Patterned Lateral Connect...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1013-ocular-dominance-and-patterned-lateral-co...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Ocular Dominance and Patterned Lateral\\nConnec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1014</td>\n",
       "      <td>1994</td>\n",
       "      <td>Associative Decorrelation Dynamics: A Theory o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1014-associative-decorrelation-dynamics-a-theo...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Associative Decorrelation Dynamics:\\nA Theory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1015</td>\n",
       "      <td>1994</td>\n",
       "      <td>A Connectionist Technique for Accelerated Text...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1015-a-connectionist-technique-for-accelerated...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Connectionist Technique for Accelerated\\nTex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1016</td>\n",
       "      <td>1994</td>\n",
       "      <td>Connectionist Speaker Normalization with Gener...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1016-connectionist-speaker-normalization-with-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Connectionist Speaker Normalization\\nwith Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1017</td>\n",
       "      <td>1994</td>\n",
       "      <td>A Critical Comparison of Models for Orientatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1017-a-critical-comparison-of-models-for-orien...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Critical Comparison of Models for\\nOrientati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1018</td>\n",
       "      <td>1994</td>\n",
       "      <td>Generalization in Reinforcement Learning: Safe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1018-generalization-in-reinforcement-learning-...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Generalization in Reinforcement Learning:\\nSaf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1019</td>\n",
       "      <td>1994</td>\n",
       "      <td>A Mixture Model System for Medical and Machine...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019-a-mixture-model-system-for-medical-and-ma...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>A Mixture Model System for Medical and\\nMachin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>102</td>\n",
       "      <td>1988</td>\n",
       "      <td>An Application of the Principle of Maximum Inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102-an-application-of-the-principle-of-maximum...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>186\\n\\nAN APPLICATION OF THE PRINCIPLE OF\\nMAX...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  year                                              title event_type  \\\n",
       "0      1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1     10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2    100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3   1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4   1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "5   1002  1994  Using a neural net to instantiate a deformable...        NaN   \n",
       "6   1003  1994           Plasticity-Mediated Competitive Learning        NaN   \n",
       "7   1004  1994  ICEG Morphology Classification using an Analog...        NaN   \n",
       "8   1005  1994  Real-Time Control of a Tokamak Plasma Using Ne...        NaN   \n",
       "9   1006  1994  Pulsestream Synapses with Non-Volatile Analogu...        NaN   \n",
       "10  1007  1994                 Learning to Play the Game of Chess        NaN   \n",
       "11  1008  1994       Multidimensional Scaling and Data Clustering        NaN   \n",
       "12  1009  1994  An experimental comparison of recurrent neural...        NaN   \n",
       "13   101  1988  Training Multilayer Perceptrons with the Exten...        NaN   \n",
       "14  1010  1994  Interference in Learning Internal Models of In...        NaN   \n",
       "15  1011  1994            Active Learning with Statistical Models        NaN   \n",
       "16  1012  1994  A Rapid Graph-based Method for Arbitrary Trans...        NaN   \n",
       "17  1013  1994  Ocular Dominance and Patterned Lateral Connect...        NaN   \n",
       "18  1014  1994  Associative Decorrelation Dynamics: A Theory o...        NaN   \n",
       "19  1015  1994  A Connectionist Technique for Accelerated Text...        NaN   \n",
       "20  1016  1994  Connectionist Speaker Normalization with Gener...        NaN   \n",
       "21  1017  1994  A Critical Comparison of Models for Orientatio...        NaN   \n",
       "22  1018  1994  Generalization in Reinforcement Learning: Safe...        NaN   \n",
       "23  1019  1994  A Mixture Model System for Medical and Machine...        NaN   \n",
       "24   102  1988  An Application of the Principle of Maximum Inf...        NaN   \n",
       "\n",
       "                                             pdf_name          abstract  \\\n",
       "0   1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1   10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2   100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3   1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4   1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "5   1002-using-a-neural-net-to-instantiate-a-defor...  Abstract Missing   \n",
       "6   1003-plasticity-mediated-competitive-learning.pdf  Abstract Missing   \n",
       "7   1004-iceg-morphology-classification-using-an-a...  Abstract Missing   \n",
       "8   1005-real-time-control-of-a-tokamak-plasma-usi...  Abstract Missing   \n",
       "9   1006-pulsestream-synapses-with-non-volatile-an...  Abstract Missing   \n",
       "10        1007-learning-to-play-the-game-of-chess.pdf  Abstract Missing   \n",
       "11  1008-multidimensional-scaling-and-data-cluster...  Abstract Missing   \n",
       "12  1009-an-experimental-comparison-of-recurrent-n...  Abstract Missing   \n",
       "13  101-training-multilayer-perceptrons-with-the-e...  Abstract Missing   \n",
       "14  1010-interference-in-learning-internal-models-...  Abstract Missing   \n",
       "15   1011-active-learning-with-statistical-models.pdf  Abstract Missing   \n",
       "16  1012-a-rapid-graph-based-method-for-arbitrary-...  Abstract Missing   \n",
       "17  1013-ocular-dominance-and-patterned-lateral-co...  Abstract Missing   \n",
       "18  1014-associative-decorrelation-dynamics-a-theo...  Abstract Missing   \n",
       "19  1015-a-connectionist-technique-for-accelerated...  Abstract Missing   \n",
       "20  1016-connectionist-speaker-normalization-with-...  Abstract Missing   \n",
       "21  1017-a-critical-comparison-of-models-for-orien...  Abstract Missing   \n",
       "22  1018-generalization-in-reinforcement-learning-...  Abstract Missing   \n",
       "23  1019-a-mixture-model-system-for-medical-and-ma...  Abstract Missing   \n",
       "24  102-an-application-of-the-principle-of-maximum...  Abstract Missing   \n",
       "\n",
       "                                           paper_text  \n",
       "0   767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1   683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2   394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3   Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4   Neural Network Ensembles, Cross\\nValidation, a...  \n",
       "5   U sing a neural net to instantiate a\\ndeformab...  \n",
       "6   Plasticity-Mediated Competitive Learning\\n\\nTe...  \n",
       "7   ICEG Morphology Classification using an\\nAnalo...  \n",
       "8   Real-Time Control of a Tokamak Plasma\\nUsing N...  \n",
       "9   Real-Time Control of a Tokamak Plasma\\nUsing N...  \n",
       "10  Learning To Play the Game of Chess\\n\\nSebastia...  \n",
       "11  Multidimensional Scaling and Data Clustering\\n...  \n",
       "12  An experimental comparison\\nof recurrent neura...  \n",
       "13  133\\n\\nTRAINING MULTILAYER PERCEPTRONS WITH TH...  \n",
       "14  Interference in Learning Internal\\nModels of I...  \n",
       "15  Active Learning with Statistical Models\\n\\nDav...  \n",
       "16  A Rapid Graph-based Method for\\nArbitrary Tran...  \n",
       "17  Ocular Dominance and Patterned Lateral\\nConnec...  \n",
       "18  Associative Decorrelation Dynamics:\\nA Theory ...  \n",
       "19  A Connectionist Technique for Accelerated\\nTex...  \n",
       "20  Connectionist Speaker Normalization\\nwith Gene...  \n",
       "21  A Critical Comparison of Models for\\nOrientati...  \n",
       "22  Generalization in Reinforcement Learning:\\nSaf...  \n",
       "23  A Mixture Model System for Medical and\\nMachin...  \n",
       "24  186\\n\\nAN APPLICATION OF THE PRINCIPLE OF\\nMAX...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('/kaggle/input/nips-papers/papers.csv')\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3841d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:02.842304Z",
     "iopub.status.busy": "2024-07-31T11:42:02.840904Z",
     "iopub.status.idle": "2024-07-31T11:42:02.855036Z",
     "shell.execute_reply": "2024-07-31T11:42:02.853671Z"
    },
    "papermill": {
     "duration": 0.044747,
     "end_time": "2024-07-31T11:42:02.858232",
     "exception": false,
     "start_time": "2024-07-31T11:42:02.813485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...\n",
       "1       683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...\n",
       "2       394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...\n",
       "3       Bayesian Query Construction for Neural\\nNetwor...\n",
       "4       Neural Network Ensembles, Cross\\nValidation, a...\n",
       "                              ...                        \n",
       "7236    Single Transistor Learning Synapses\\n\\nPaul Ha...\n",
       "7237    Bias, Variance and the Combination of\\nLeast S...\n",
       "7238    A Real Time Clustering CMOS\\nNeural Engine\\nT....\n",
       "7239    Learning direction in global motion: two\\nclas...\n",
       "7240    Correlation and Interpolation Networks for\\nRe...\n",
       "Name: paper_text, Length: 7241, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paper_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487480c",
   "metadata": {
    "papermill": {
     "duration": 0.025028,
     "end_time": "2024-07-31T11:42:02.907959",
     "exception": false,
     "start_time": "2024-07-31T11:42:02.882931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* the column of interest is **paper_text** so I will ignore the others.\n",
    "* You can adjust the **index** to refer to the specific paper you want to summarize.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c5bc78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:02.963928Z",
     "iopub.status.busy": "2024-07-31T11:42:02.963457Z",
     "iopub.status.idle": "2024-07-31T11:42:02.973453Z",
     "shell.execute_reply": "2024-07-31T11:42:02.971902Z"
    },
    "papermill": {
     "duration": 0.040843,
     "end_time": "2024-07-31T11:42:02.976494",
     "exception": false,
     "start_time": "2024-07-31T11:42:02.935651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U sing a neural net to instantiate a\\ndeformable model\\nChristopher K. I. Williams; Michael D. Revowand Geoffrey E. Hinton\\nDepartment of Computer Science, University of Toronto\\nToronto, Ontario, Canada M5S lA4\\n\\nAbstract\\nDeformable models are an attractive approach to recognizing nonrigid objects which have considerable within class variability. However, there are severe search problems associated with fitting the\\nmodels to data. We show that by using neural networks to provide\\nbetter starting points, the search time can be significantly reduced.\\nThe method is demonstrated on a character recognition task.\\nIn previous work we have developed an approach to handwritten character recognition based on the use of deformable models (Hinton, Williams and Revow, 1992a;\\nRevow, Williams and Hinton, 1993). We have obtained good performance with this\\nmethod, but a major problem is that the search procedure for fitting each model to\\nan image is very computationally intensive, because there is no efficient algorithm\\n(like dynamic programming) for this task. In this paper we demonstrate that it is\\npossible to \"compile down\" some of the knowledge gained while fitting models to\\ndata to obtain better starting points that significantly reduce the search time.\\n\\n1\\n\\nDEFORMABLE MODELS FOR DIGIT RECOGNITION\\n\\nThe basic idea in using deformable models for digit recognition is that each digit has\\na model, and a test image is classified by finding the model which is most likely to\\nhave generated it. The quality of the match between model and test image depends\\non the deformation of the model, the amount of ink that is attributed to noise and\\nthe distance of the remaining ink from the deformed model.\\n?Current address: Department of Computer Science and Applied Mathematics, Aston\\nUniversity, Birmingham B4 7ET, UK.\\n\\n\\x0c966\\n\\nChristopher K. T. Williams, Michael D. Revow, Geoffrey E. Hinton\\n\\nMore formally, the two important terms in assessing the fit are the prior probability distribution for the instantiation parameters of a model (which penalizes very\\ndistorted models), and the imaging model that characterizes the probability distribution over possible images given the instantiated model l . Let I be an image, M\\nbe a model and z be its instantiation parameters. Then the evidence for model M\\nis given by\\nP(IIM)\\n\\n=\\n\\nJ\\n\\nP(zIM)P(IIM, z)dz\\n\\n(1)\\n\\nThe first term in the integrand is the prior on the instantiation parameters and the\\nsecond is the imaging model i.e., the likelihood of the data given the instantiated\\nmodel. P(MII) is directly proportional to P(IIM), as we assume a uniform prior\\non each digit.\\nEquation 1 is formally correct, but if z has more than a few dimensions the evaluation of this integral is very computationally intensive. However, it is often possible\\nto make an approximation based on the assumption that the integrand is strongly\\npeaked around a (global) maximum value z*. In this case, the evidence can be approximated by the highest peak of the integrand times a volume factor ~(zII, M),\\nwhich measures the sharpness of the peak 2 .\\nP(IIM) ~ P(z*IM)P(Ilz*, M)~(zII, M)\\n\\n(2)\\n\\nBy Taylor expanding around z* to second order it can be shown that the volume\\nfactor depends on the determinant of the Hessian of 10gP(z, 11M) . Taking logs\\nof equation 2, defining EdeJ as the negative log of P(z*IM), and EJit as the corresponding term for the imaging model, then the aim of the search is to find the\\nminimum of E tot = EdeJ + EJit . Of course the total energy will have many local\\nminima; for the character recognition task we aim to find the global minimum by\\nusing a continuation method (see section 1.2).\\n1.1\\n\\nSPLINES, AFFINE TRANSFORMS AND IMAGING MODELS\\n\\nThis section presents a brief overview of our work on using deformable models for\\ndigit recognition. For a fuller treatment, see Revow, Williams and Hinton (1993) .\\nEach digit is modelled by a cubic B-spline whose shape is determined by the positions of the control points in the object-based frame. The models have eight control\\npoints, except for the one model which has three, and the seven model which has\\nfive. To generate an ideal example of a digit the control points are positioned at\\ntheir \"home\" locations. Deformed characters are produced by perturbing the control points away from their home locations. The home locations and covariance\\nmatrix for each model were adapted in order to improve the performance.\\nThe deformation energy only penalizes shape deformations. Affine transformations,\\ni.e., translation, rotation, dilation, elongation, and shear, do not change the underlying shape of an object so we want the deformation energy to be invariant under\\nthem . We achieve this by giving each model its own \"object-based frame\" and\\ncomputing the deformation energy relative to this frame.\\nlThis framework has been used by many authors, e.g. Grenander et al (1991) .\\n2The Gaussian approximation has been popularized in the neural net community by\\nMacKay (1992) .\\n\\n\\x0cUsing a Neural Net to Instantiate a Deformable Model\\n\\n967\\n\\nThe data we used consists of binary-pixel images of segmented handwritten digits.\\nThe general flavour of a imaging model for this problem is that there should be a\\nhigh probability of inked pixels close to the spline, and lower probabilities further\\naway. This can be achieved by spacing out a number of Gaussian \"ink generators\"\\nuniformly along the contour; we have found that it is also useful to have a uniform\\nbackground noise process over the area of the image that is able to account for\\npixels that occur far away from the generators. The ink generators and background\\nprocess define a mixture model. Using the assumption that each data point is\\ngenerated independently given the instantiated model, P(Ilz*, M) factors into the\\nproduct of the probability density of each black pixel under the mixture model.\\n\\n1.2\\n\\nRECOGNIZING ISOLATED DIGITS\\n\\nFor each model, the aim of the search is to find the instantiation parameters that\\nminimize E tot . The search starts with zero deformations and an initial guess for\\nthe affine parameters which scales the model so as to lie over the data with zero\\nskew and rotation. A small number of generators with the same large variance are\\nplaced along the spline, forming a broad, smooth ridge of high ink-probability along\\nthe spline. We use a search procedure similar to the (iterative) Expectation Maximization (EM) method of fitting an unconstrained mixture of Gaussians, except\\nthat (i) the Gaussians are constrained to lie on the spline (ii) there is a deformation energy term and (iii) the affine transformation must be recalculated on each\\niteration. During the search the number of generators is gradually increased while\\ntheir variance decreases according to predetermined \"annealing\" schedule3 .\\nAfter fitting all the models to a particular image, we wish to evaluate which of the\\nmodels best \"explains\" the data. The natural measure is the sum of Ejit, Edej\\nand the volume factor. However, we have found that performance is improved by\\nincluding four additional terms which are easily obtained from the final fits of the\\nmodel to the image. These are (i) a measure which penalizes matches in which\\nthere are beads far from any inked pixels (the \"beads in white space\" problem),\\nand (ii) the rotation, shear and elongation of the affine transform. It is hard to\\ndecide in a principled way on the correct weightings for all of these terms in the\\nevaluation function. We estimated the weightings from the data by training a\\nsimple postprocessing neural network. These inputs are connected directly to the\\nten output units. The output units compete using the \"softmax\" function which\\nguarantees that they form a probability distribution, summing to one.\\n\\n2\\n\\nPREDICTING THE INSTANTIATION PARAMETERS\\n\\nThe search procedure described above is very time consuming. However, given many\\nexamples of images and the corresponding instantiation parameters obtained by the\\nslow method, it is possible to train a neural network to predict the instantiation\\nparameters of novel images. These predictions provide better starting points, so the\\nsearch time can be reduced.\\n3The schedule starts with 8 beads increasing to 60 beads in six steps, with the variance\\ndecreasing from 0.04 to 0.0006 (measured in the object frame). The scale is set in the\\nobject-based frame so that each model is 1 unit high.\\n\\n\\x0c968\\n\\n2.1\\n\\nChristopher K. I. Williams, Michael D. Revow, Geoffrey E. Hinton\\n\\nPREVIOUS WORK\\n\\nPrevious work on hypothesizing instantiation parameters can be placed into two\\nbroad classes, correspondence based search and parameter space search. In correspondence based search, the idea is to extract features from the image and identify\\ncorresponding features in the model. Using sufficient correspondences the instantiation parameters of the model can be determined. The problem is that simple, easily\\ndetectable image features have many possible matches, and more complex features\\nrequire more computation and are more difficult to detect. Grimson (1990) shows\\nhow to search the space of possible correspondences using an interpretation tree.\\nAn alternative approach, which is used in Hough transform techniques, is to directly work in parameter space. The Hough transform was originally designed for\\nthe detection of straight lines in images, and has been extended to cover a number\\nof geometric shapes, notably conic sections. Ballard (1981) further extended the\\napproach to arbitrary shapes with the Generalized Hough Transform . The parameter space for each model is divided into cells (\"binned\"), and then for each image\\nfeature a vote is added to each parameter space bin that could have produced that\\nfeature. After collecting votes from all image features we then search for peaks in\\nthe parameter space accumulator array, and attempt to verify pose. The Hough\\ntransform can be viewed as a crude way of approximating the logarithm of the\\nposterior distribution P(zII, M) (e.g. Hunt et al , 1988).\\nHowever, these two techniques have only been used on problems involving rigid\\nmodels, and are not readily applicable to the digit recognition problem. For the\\nHough space method, binning and vote collection is impractical in the high dimensional parameter space, and for the correspondence based approach there is a\\nlack of easily identified and highly discriminative features. The strengths of these\\ntwo techniques, namely their ability to deal with arbitrary scalings, rotations and\\ntranslations of the data, and their tolerance of extraneous features, are not really\\nrequired for a task where the input data is fairly well segmented and normalized.\\nOur approach is to use a neural network to predict the instantiation parameters for\\neach model, given an input image. Zemel and Hinton (1991) used a similar method\\nwith simple 2-d objects, and more recently, Beymer et al (1993) have constructed\\na network which maps from a face image to a 2-d parameter space spanning head\\nrotations and a smile/no-smile dimension. However, their method does not directly\\nmap from images to instantiation parameters; they use a computer vision correspondence algorithm to determine the displacement field of pixels in a novel image\\nrelative to a reference image, and then use this field as the input to the network.\\nThis step limits the use of the approach to images that are sufficiently similar so\\nthat the correspondence algorithm functions well.\\n\\n2.2\\n\\nINSTANTIATING DIGIT MODELS USING NEURAL\\nNETWORKS\\nThe network which is used to predict the model instantiation parameters is shown\\nin figure 1. The (unthinned) binary images are normalized to give 16 x 16 8-bit\\ngreyscale images which are fed into the neural network. The network uses a standard\\nthree-layer architecture; each hidden unit computes a weighted sum of its inputs,\\nand then feeds this value through a sigmoidal nonlinearity u(x) = 1/(1 + e- X ). The\\n\\n\\x0cUsing a Neural Net to Instantiate a Deformable Model\\n\\ncps for 0 model\\n\\ncps for I model\\n\\n969\\n\\ncps for 9 model\\n\\no\\n\\nFigure 1: The prediction network architecture. \"cps\" stands for control points.\\noutput values are a weighted linear combination of the hidden unit activities plus\\noutput biases. The targets are the locations of the control points in the normalized\\nimage, found from fitting models as described in section 1.2.\\nThe network was trained with backpropagation to minimize the squared error, using\\n900 training images and 200 validation images of each digit drawn from the br\\nset of the CEDAR CDROM 1 database of Cities, States, ZIP Codes, Digits, and\\nAlphabetic Characters4 . Two test sets were used; one was obtained from data in the\\nbr dataset, and the other was the (official) bs test set. After some experimentation\\nwe chose a network with twenty hidden units, which means that the net has over\\n8,000 weights . With such a large number of weights it is important to regularize the\\nsolution obtained by the network by using a complexity penalty; we used a weight\\nand optimized A on a validation set. Targets were only set for the\\npenalty AL: j\\ncorrect digit at the output layer; nothing was backpropagated from the other output\\nunits. The net took 440 epochs to train using the default conjugate gradient search\\nmethod in the Xerion neural network simulator 5 . It would be possible to construct\\nten separate networks to carry out the same task as the net described above, but\\nthis would intensify the danger of overfitting, which is reduced by giving the network\\na common pool of hidden units which it can use as it decides appropriate.\\n\\nwJ\\n\\nFor comparison with the prediction net described above, a trivial network which\\njust consisted of output biases was trained; this network simply learns the average\\nvalue of the control point locations. On a validation set the squared error of the\\nprediction net was over three times smaller than the trivial net. Although this is\\nencouraging, the acid test is to compare the performance of elastic models settled\\nfrom the predicted positions using a shortened annealing schedule; if the predictions\\nare good, then only a short amount of settling will be required.\\n4Made available by the Unites States Postal Service Office of Advanced Technology.\\n5Xerion was designed and implemented by Drew van Camp, Tony Plate and Geoffrey\\nHinton at the University of Toronto.\\n\\n\\x0c970\\n\\nChristopher K. I. Williams, Michael D. Revow, Geoffrey E. Hinton\\n\\nFigure 2: A comparision of the initial instantiations due to the prediction net (top row)\\nand the trivial net (bottom row) on an image of a 2. Notice that for the two model the\\nprediction net is much closer to the data. The other digit models mayor may not be greatly\\naffected by the input data; for example, the predictions from both nets seem essentially\\nthe same for the zero, but for the seven the prediction net puts the model nearer to the\\ndata.\\nThe feedforward net predicts the position of the control points in the normalized\\nimage. By inverting the normalization process, the positions of the control points\\nin the un-normalized image are determined. The model deformation and affine\\ntransformation corresponding to these image control point locations can then be\\ndetermined by running a part of one iteration of the search procedure. Experiments\\nwere then conducted with a number of shortened annealing schedules; for each one,\\ndata obtained from settling on a part of the training data was used to train the\\npostprocessing net. The performance was then evaluated on the br test set.\\nThe full annealing schedule has six stages. The shortened annealing schedules are:\\n1. No settling at all\\n2. Two iterations at the final variance of 0.0006\\n3. One iteration at 0.0025 and two at 0.0006\\n4. The full annealing schedule (for comparison)\\nThe results on the br test set are shown in table 1. The general trends are that the\\nperformance obtained using the prediction net is consistently better than the trivial\\nnet, and that longer annealing schedules lead to better performance. A comparison\\nof schedules 3 and 4 in table 1 indicates that the performance of the prediction\\nnet/schedule 3 combination is similar to (or slightly better than) that obtained\\nwith the full annealing schedule, and is more than a factor of two faster. The\\nresults with the full schedule are almost identical to the results obtained with the\\ndefault \"box\" initialization described in section 1.2. Figure 2 compares the outputs\\nof the prediction and trivial nets on a particular example. Judging from the weight\\n\\n\\x0cUsing a Neural Net to Instantiate a Deformable Model\\n\\nSchedule number\\n\\nTrivial net\\n\\nPrediction net\\n\\n1\\n2\\n3\\n4\\n\\n427\\n329\\n160\\n40\\n\\n200\\n58\\n32\\n36\\n\\n971\\n\\nAverage time required\\nto settle one model (s)\\n0.12\\n0.25\\n0.49\\n1.11\\n\\nTable 1: Errors on the internal test set of 2000 examples for different annealing schedules.\\nThe timing trials were carried out on a R-4400 machine.\\n\\nvectors and activity patterns of the hidden units, it does not seem that some of the\\nunits are specialized for a particular digit class.\\nA run on the bs test set using schedule 3 gave an error rate of 4.76 % (129 errors),\\nwhich is very similar to the 125 errors obtained using the full annealing schedule\\nand the box initialization. A comparison of the errors made on the two runs shows\\nthat only 67 out of the 129 errors were common to the two sets. This suggests that\\nit would be very sensible to reject cases where the two methods do not agree.\\n\\n3\\n\\nDISCUSSION\\n\\nThe prediction net used above can be viewed as an interpolation scheme in the\\ncontrol point position space of each digit z(I) = Zo + 2:i ai(I)zi, where z(I) is\\nthe predicted position in the control point space, Zo is the contribution due to the\\nbiases, ai is the activity of hidden unit i and Zi is its location in the control point\\nposition space (learned from the data) . If there are more hidden units than output\\ndimensions, then for any particular image there are an infinite number of ways to\\nmake this equation hold exactly. However, the network will tend to find solutions\\nso that the ai(I)\\'s will vary smoothly as the image is perturbed.\\nThe nets described above output just one set of instantiation parameters for a\\ngiven model. However, it may be preferable to be able to represent a number of\\nguesses about model instantiation parameters; one way of doing this is to train a\\nnetwork that has multiple sets of output parameters, as in the \"mixture of experts\"\\narchitecture of Jacobs et aI (1991). The outputs can be interpreted as a mixture\\ndistribution in the control point position space, conditioned on the input image.\\nAnother approach to providing more information about the posterior distribution\\nis described in (Hinton, Williams and Revow, 1992b), where P(zlI) is approximated\\nusing a fixed set of basis functions whose weighting depends on the input image I.\\nThe strategies descriped above directly predict the instantiation parameters in parameter space. It is also possible to use neural networks to hypothesize correspondences, i.e. to predict an inked pixel\\'s position on the spline given a local window\\nof context in the image. With sufficient matches it is then possible to compute\\nthe instantiation parameters of the model. We have conducted some preliminary\\nexperiments with this method (described in Williams, 1994), which indicate that\\ngood performance can be achieved for the correspondence prediction task.\\n\\n\\x0c972\\n\\nChristopher K. I. Williams, Michael D. Revow, Geoffrey E. Hinton\\n\\nWe have shown that the we can obtain significant speedup using the prediction net.\\nThe schemes outlined above which allow multimodal predictions in instantiation\\nparameter space may improve performance and deserve further investigation. We\\nare also interested in improving the performance of the prediction net, for example\\nby outputting a confidence measure which could be used to adjust the length of\\nthe elastic models\\' search appropriately. We believe that using machine learning\\ntechniques like neural networks to help reduce the amount of search required to fit\\ncomplex models to data may be useful for many other problems.\\nAcknowledgements\\nThis research was funded by Apple and by the Ontario Information Technology Research\\nCentre. We thank Allan Jepson, Richard Durbin, Rich Zemel, Peter Dayan, Rob Tibshirani\\nand Yann Le Cun for helpful discussions. Geoffrey Hinton is the Noranda Fellow of the\\nCanadian Institute for Advanced Research.\\n\\nReferences\\nBallard, D. H. (1981). Generalizing the Hough transfrom to detect arbitrary shapes.\\nPattern Recognition, 13(2):111-122.\\nBeymer, D., Shashua, A., and Poggio, T . (1993). Example Based Image Analysis and\\nSynthesis. AI Memo 1431, AI Laboratory, MIT.\\nGrenander, U., Chow, Y., and Keenan, D. M. (1991). Hands: A pattern theoretic study of\\nbiological shapes. Springer-Verlag.\\nGrimson, W. E. 1. (1990) . Object recognition by computer. MIT Press, Cambridge, MA.\\nHinton, G. E., Williams, C. K. 1., and Revow, M. D. (1992a). Adaptive elastic models\\nfor hand-printed character recognition. In Moody, J. E., Hanson, S. J., and Lippmann, R. P., editors, Advances in Neural Information Processing Systems 4. Morgan\\nKauffmann.\\nHinton, G. E., Williams, C. K. 1., and Revow, M. D. (1992b). Combinining two methods\\nof recognizing hand-printed digits. In Aleksander, 1. and Taylor, J., editors, Artificial\\nNeural Networks 2. Elsevier Science Publishers.\\nHunt, D. J., Nolte, L. W., and Ruedger, W . H. (1988) . Performance of the Hough Transform and its Relationship to Statistical Signal Detection Theory. Computer Vision,\\nGraphics and Image Processing, 43:221- 238.\\nJacobs, R. A., Jordan, M. 1., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive mixtures\\nof local experts. Neural Computation, 3(1).\\nMacKay, D. J. C. (1992). Bayesian Interpolation. Neural Computation, 4(3):415-447.\\nRevow, M. D., Williams, C. K. 1., and Hinton, G. E. (1993) . Using mixtures of deformable\\nmodels to capture variations in hand printed digits. In Srihari, S., editor, Proceedings\\nof the Third International Workshop on Frontiers in Handwriting Recognition, pages\\n142-152, Buffalo, New York, USA.\\nWilliams, C. K. 1. (1994) . Combining deformable models and neural networks for handprinted digit recognition. PhD thesis, Dept. of Computer Science, University of\\nToronto.\\nZemel, R . S. and Hinton, G. E. (1991) . Discovering viewpoint-invariant relationships that\\ncharacterize objects. In Lippmann, R. P., Moody, J. E., and Touretzky, D. S., editors, Advances In Neural Information Processing Systems 3, pages 299-305. Morgan\\nKaufmann Publishers.\\n\\n\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_of_paper=5\n",
    "text=df['paper_text'][index_of_paper]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1022e7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:03.031022Z",
     "iopub.status.busy": "2024-07-31T11:42:03.030529Z",
     "iopub.status.idle": "2024-07-31T11:42:13.037939Z",
     "shell.execute_reply": "2024-07-31T11:42:13.036191Z"
    },
    "papermill": {
     "duration": 10.039534,
     "end_time": "2024-07-31T11:42:13.041029",
     "exception": false,
     "start_time": "2024-07-31T11:42:03.001495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "import nltk\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9524ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T11:12:40.853173Z",
     "iopub.status.busy": "2024-07-29T11:12:40.852220Z",
     "iopub.status.idle": "2024-07-29T11:12:40.857593Z",
     "shell.execute_reply": "2024-07-29T11:12:40.856399Z",
     "shell.execute_reply.started": "2024-07-29T11:12:40.853129Z"
    },
    "papermill": {
     "duration": 0.028545,
     "end_time": "2024-07-31T11:42:13.096193",
     "exception": false,
     "start_time": "2024-07-31T11:42:13.067648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a837fae",
   "metadata": {
    "papermill": {
     "duration": 0.02548,
     "end_time": "2024-07-31T11:42:13.148247",
     "exception": false,
     "start_time": "2024-07-31T11:42:13.122767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**steps**:\n",
    "*     Converts text to lowercase.\n",
    "*      Removes HTML tags.\n",
    "*      Removes digits.\n",
    "*      Removes URLs and links.\n",
    "*      Removes single characters followed by a period.\n",
    "*      Removes parentheses and their contents.\n",
    "*      Tokenizes the text into words.\n",
    "*      Removes  stopwords.\n",
    "*      Joins the cleaned tokens into a single string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a34d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:13.202734Z",
     "iopub.status.busy": "2024-07-31T11:42:13.201870Z",
     "iopub.status.idle": "2024-07-31T11:42:13.212877Z",
     "shell.execute_reply": "2024-07-31T11:42:13.211287Z"
    },
    "papermill": {
     "duration": 0.041767,
     "end_time": "2024-07-31T11:42:13.215822",
     "exception": false,
     "start_time": "2024-07-31T11:42:13.174055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def txt_processing(doc_text):\n",
    "    \n",
    "    doc_text = doc_text.lower() #convert to lower case        \n",
    "    doc_text = BeautifulSoup(doc_text, \"html.parser\").text # Remove HTML tag       \n",
    "    doc_text = re.sub(r'\\d+', '', doc_text) # Remove digits \n",
    "    doc_text = re.sub(r'http\\S+|www\\S+|https\\S+', '', doc_text, flags=re.MULTILINE)# Remove links\n",
    "    doc_text = re.sub(r'\\b\\w\\.\\b', '', doc_text)\n",
    "    doc_text = re.sub(r'\\(.*?\\)', '', doc_text)  # Removes () and their contents\n",
    "   \n",
    "    tokens = word_tokenize(doc_text) # Tokenize\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]# Remove stopwords  \n",
    "   \n",
    "   \n",
    "    cleaned_doc = ' '.join(tokens) # join as a string\n",
    "    \n",
    "    return tokens,cleaned_doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "598b1167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:13.270158Z",
     "iopub.status.busy": "2024-07-31T11:42:13.269675Z",
     "iopub.status.idle": "2024-07-31T11:42:14.422719Z",
     "shell.execute_reply": "2024-07-31T11:42:14.421052Z"
    },
    "papermill": {
     "duration": 1.184999,
     "end_time": "2024-07-31T11:42:14.426628",
     "exception": false,
     "start_time": "2024-07-31T11:42:13.241629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "tokens,doc = txt_processing(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b89cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:14.483606Z",
     "iopub.status.busy": "2024-07-31T11:42:14.482608Z",
     "iopub.status.idle": "2024-07-31T11:42:14.489493Z",
     "shell.execute_reply": "2024-07-31T11:42:14.487983Z"
    },
    "papermill": {
     "duration": 0.03811,
     "end_time": "2024-07-31T11:42:14.492750",
     "exception": false,
     "start_time": "2024-07-31T11:42:14.454640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u sing neural net instantiate deformable model christopher k. i. williams ; michael d. revowand geoffrey e. hinton department computer science , university toronto toronto , ontario , canada ms la abstract deformable models attractive approach recognizing nonrigid objects considerable within class variability . however , severe search problems associated fitting models data . show using neural networks provide better starting points , search time significantly reduced . method demonstrated character recognition task . previous work developed approach handwritten character recognition based use deformable models ( hinton , williams revow , ; revow , williams hinton , ) . obtained good performance method , major problem search procedure fitting model image computationally intensive , efficient algorithm task . paper demonstrate possible `` compile '' knowledge gained fitting models data obtain better starting points significantly reduce search time . deformable models digit recognition basic idea using deformable models digit recognition digit model , test image classified finding model likely generated . quality match model test image depends deformation model , amount ink attributed noise distance remaining ink deformed model . ? current address : department computer science applied mathematics , aston university , birmingham b et , uk . christopher k. t. williams , michael d. revow , geoffrey e. hinton formally , two important terms assessing fit prior probability distribution instantiation parameters model ( penalizes distorted models ) , imaging model characterizes probability distribution possible images given instantiated model l . let image , model z instantiation parameters . evidence model given p = j ppdz first term integrand prior instantiation parameters second imaging model e. , likelihood data given instantiated model . p directly proportional p , assume uniform prior digit . equation formally correct , z dimensions evaluation integral computationally intensive . however , often possible make approximation based assumption integrand strongly peaked around maximum value z* . case , evidence approximated highest peak integrand times volume factor ~ , measures sharpness peak . p ~ pp~ taylor expanding around z* second order shown volume factor depends determinant hessian gp . taking logs equation , defining edej negative log p , ejit corresponding term imaging model , aim search find minimum e tot = edej + ejit . course total energy many local minima ; character recognition task aim find global minimum using continuation method . . splines , affine transforms imaging models section presents brief overview work using deformable models digit recognition . fuller treatment , see revow , williams hinton . digit modelled cubic b-spline whose shape determined positions control points object-based frame . models eight control points , except one model three , seven model five . generate ideal example digit control points positioned `` home '' locations . deformed characters produced perturbing control points away home locations . home locations covariance matrix model adapted order improve performance . deformation energy penalizes shape deformations . affine transformations , e. , translation , rotation , dilation , elongation , shear , change underlying shape object want deformation energy invariant . achieve giving model `` object-based frame '' computing deformation energy relative frame . lthis framework used many authors , g. grenander et al . gaussian approximation popularized neural net community mackay . using neural net instantiate deformable model data used consists binary-pixel images segmented handwritten digits . general flavour imaging model problem high probability inked pixels close spline , lower probabilities away . achieved spacing number gaussian `` ink generators '' uniformly along contour ; found also useful uniform background noise process area image able account pixels occur far away generators . ink generators background process define mixture model . using assumption data point generated independently given instantiated model , p factors product probability density black pixel mixture model . . recognizing isolated digits model , aim search find instantiation parameters minimize e tot . search starts zero deformations initial guess affine parameters scales model lie data zero skew rotation . small number generators large variance placed along spline , forming broad , smooth ridge high ink-probability along spline . use search procedure similar expectation maximization method fitting unconstrained mixture gaussians , except gaussians constrained lie spline deformation energy term affine transformation must recalculated iteration . search number generators gradually increased variance decreases according predetermined `` annealing '' schedule . fitting models particular image , wish evaluate models best `` explains '' data . natural measure sum ejit , edej volume factor . however , found performance improved including four additional terms easily obtained final fits model image . measure penalizes matches beads far inked pixels , rotation , shear elongation affine transform . hard decide principled way correct weightings terms evaluation function . estimated weightings data training simple postprocessing neural network . inputs connected directly ten output units . output units compete using `` softmax '' function guarantees form probability distribution , summing one . predicting instantiation parameters search procedure described time consuming . however , given many examples images corresponding instantiation parameters obtained slow method , possible train neural network predict instantiation parameters novel images . predictions provide better starting points , search time reduced . schedule starts beads increasing beads six steps , variance decreasing . . . scale set object-based frame model unit high . . christopher k. i. williams , michael d. revow , geoffrey e. hinton previous work previous work hypothesizing instantiation parameters placed two broad classes , correspondence based search parameter space search . correspondence based search , idea extract features image identify corresponding features model . using sufficient correspondences instantiation parameters model determined . problem simple , easily detectable image features many possible matches , complex features require computation difficult detect . grimson shows search space possible correspondences using interpretation tree . alternative approach , used hough transform techniques , directly work parameter space . hough transform originally designed detection straight lines images , extended cover number geometric shapes , notably conic sections . ballard extended approach arbitrary shapes generalized hough transform . parameter space model divided cells , image feature vote added parameter space bin could produced feature . collecting votes image features search peaks parameter space accumulator array , attempt verify pose . hough transform viewed crude way approximating logarithm posterior distribution p . however , two techniques used problems involving rigid models , readily applicable digit recognition problem . hough space method , binning vote collection impractical high dimensional parameter space , correspondence based approach lack easily identified highly discriminative features . strengths two techniques , namely ability deal arbitrary scalings , rotations translations data , tolerance extraneous features , really required task input data fairly well segmented normalized . approach use neural network predict instantiation parameters model , given input image . zemel hinton used similar method simple -d objects , recently , beymer et al constructed network maps face image -d parameter space spanning head rotations smile/no-smile dimension . however , method directly map images instantiation parameters ; use computer vision correspondence algorithm determine displacement field pixels novel image relative reference image , use field input network . step limits use approach images sufficiently similar correspondence algorithm functions well . . instantiating digit models using neural networks network used predict model instantiation parameters shown figure . binary images normalized give x -bit greyscale images fed neural network . network uses standard three-layer architecture ; hidden unit computes weighted sum inputs , feeds value sigmoidal nonlinearity u = / . using neural net instantiate deformable model cps model cps model cps model figure : prediction network architecture . `` cps '' stands control points . output values weighted linear combination hidden unit activities plus output biases . targets locations control points normalized image , found fitting models described section .. network trained backpropagation minimize squared error , using training images validation images digit drawn br set cedar cdrom database cities , states , zip codes , digits , alphabetic characters . two test sets used ; one obtained data br dataset , bs test set . experimentation chose network twenty hidden units , means net , weights . large number weights important regularize solution obtained network using complexity penalty ; used weight optimized validation set . targets set penalty al : j correct digit output layer ; nothing backpropagated output units . net took epochs train using default conjugate gradient search method xerion neural network simulator . would possible construct ten separate networks carry task net described , would intensify danger overfitting , reduced giving network common pool hidden units use decides appropriate . wj comparison prediction net described , trivial network consisted output biases trained ; network simply learns average value control point locations . validation set squared error prediction net three times smaller trivial net . although encouraging , acid test compare performance elastic models settled predicted positions using shortened annealing schedule ; predictions good , short amount settling required . made available unites states postal service office advanced technology . xerion designed implemented drew van camp , tony plate geoffrey hinton university toronto . christopher k. i. williams , michael d. revow , geoffrey e. hinton figure : comparision initial instantiations due prediction net trivial net image . notice two model prediction net much closer data . digit models mayor may greatly affected input data ; example , predictions nets seem essentially zero , seven prediction net puts model nearer data . feedforward net predicts position control points normalized image . inverting normalization process , positions control points un-normalized image determined . model deformation affine transformation corresponding image control point locations determined running part one iteration search procedure . experiments conducted number shortened annealing schedules ; one , data obtained settling part training data used train postprocessing net . performance evaluated br test set . full annealing schedule six stages . shortened annealing schedules : . settling . two iterations final variance . . one iteration . two . . full annealing schedule results br test set shown table . general trends performance obtained using prediction net consistently better trivial net , longer annealing schedules lead better performance . comparison schedules table indicates performance prediction net/schedule combination similar obtained full annealing schedule , factor two faster . results full schedule almost identical results obtained default `` box '' initialization described section .. figure compares outputs prediction trivial nets particular example . judging weight using neural net instantiate deformable model schedule number trivial net prediction net average time required settle one model . . . . table : errors internal test set examples different annealing schedules . timing trials carried r- machine . vectors activity patterns hidden units , seem units specialized particular digit class . run bs test set using schedule gave error rate . % , similar errors obtained using full annealing schedule box initialization . comparison errors made two runs shows errors common two sets . suggests would sensible reject cases two methods agree . discussion prediction net used viewed interpolation scheme control point position space digit z = zo + : aizi , z predicted position control point space , zo contribution due biases , ai activity hidden unit zi location control point position space . hidden units output dimensions , particular image infinite number ways make equation hold exactly . however , network tend find solutions ai 's vary smoothly image perturbed . nets described output one set instantiation parameters given model . however , may preferable able represent number guesses model instantiation parameters ; one way train network multiple sets output parameters , `` mixture experts '' architecture jacobs et ai . outputs interpreted mixture distribution control point position space , conditioned input image . another approach providing information posterior distribution described , p approximated using fixed set basis functions whose weighting depends input image i. strategies descriped directly predict instantiation parameters parameter space . also possible use neural networks hypothesize correspondences , e. predict inked pixel 's position spline given local window context image . sufficient matches possible compute instantiation parameters model . conducted preliminary experiments method , indicate good performance achieved correspondence prediction task . christopher k. i. williams , michael d. revow , geoffrey e. hinton shown obtain significant speedup using prediction net . schemes outlined allow multimodal predictions instantiation parameter space may improve performance deserve investigation . also interested improving performance prediction net , example outputting confidence measure could used adjust length elastic models ' search appropriately . believe using machine learning techniques like neural networks help reduce amount search required fit complex models data may useful many problems . acknowledgements research funded apple ontario information technology research centre . thank allan jepson , richard durbin , rich zemel , peter dayan , rob tibshirani yann le cun helpful discussions . geoffrey hinton noranda fellow canadian institute advanced research . references ballard , d. h. . generalizing hough transfrom detect arbitrary shapes . pattern recognition , : - . beymer , d. , shashua , a. , poggio , . . example based image analysis synthesis . ai memo , ai laboratory , mit . grenander , u. , chow , y. , keenan , d. m. . hands : pattern theoretic study biological shapes . springer-verlag . grimson , w. e. . . object recognition computer . mit press , cambridge , . hinton , g. e. , williams , c. k . . , revow , m. d. . adaptive elastic models hand-printed character recognition . moody , j. e. , hanson , s. j. , lippmann , r. p. , editors , advances neural information processing systems . morgan kauffmann . hinton , g. e. , williams , c. k . . , revow , m. d. . combinining two methods recognizing hand-printed digits . aleksander , . taylor , j. , editors , artificial neural networks . elsevier science publishers . hunt , d. j. , nolte , l. w. , ruedger , w . h. . performance hough transform relationship statistical signal detection theory . computer vision , graphics image processing , : - . jacobs , r. a. , jordan , . . , nowlan , s. j. , hinton , g. e. . adaptive mixtures local experts . neural computation , . mackay , d. j. c. . bayesian interpolation . neural computation , : - . revow , m. d. , williams , c. k . . , hinton , g. e. . using mixtures deformable models capture variations hand printed digits . srihari , s. , editor , proceedings third international workshop frontiers handwriting recognition , pages - , buffalo , new york , usa . williams , c. k. . . combining deformable models neural networks handprinted digit recognition . phd thesis , dept . computer science , university toronto . zemel , r . s. hinton , g. e. . discovering viewpoint-invariant relationships characterize objects . lippmann , r. p. , moody , j. e. , touretzky , d. s. , editors , advances neural information processing systems , pages - . morgan kaufmann publishers .\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9e9f7",
   "metadata": {
    "papermill": {
     "duration": 0.026405,
     "end_time": "2024-07-31T11:42:14.544723",
     "exception": false,
     "start_time": "2024-07-31T11:42:14.518318",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# POS Tag Overview for Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d3a6c",
   "metadata": {
    "papermill": {
     "duration": 0.026508,
     "end_time": "2024-07-31T11:42:14.597849",
     "exception": false,
     "start_time": "2024-07-31T11:42:14.571341",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**POS** \n",
    "* > refers to **P**art **o**f **S**peech\n",
    "* > involves assigning a **grammatical** category to each word in a text,** such as noun, verb, adjective, etc.**\n",
    "* > This helps in **understanding the syntactic structure of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69cbb8e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:14.650713Z",
     "iopub.status.busy": "2024-07-31T11:42:14.650294Z",
     "iopub.status.idle": "2024-07-31T11:42:15.192945Z",
     "shell.execute_reply": "2024-07-31T11:42:15.191363Z"
    },
    "papermill": {
     "duration": 0.572945,
     "end_time": "2024-07-31T11:42:15.196291",
     "exception": false,
     "start_time": "2024-07-31T11:42:14.623346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token           Part-of-Speech \n",
      "------------------------------\n",
      "u               NOUN           \n",
      "sing            VERB           \n",
      "neural          ADJ            \n",
      "net             ADJ            \n",
      "instantiate     ADJ            \n",
      "deformable      ADJ            \n",
      "model           NOUN           \n",
      "christopher     PROPN          \n",
      "k.              PROPN          \n",
      "i.              PROPN          \n",
      "williams        PROPN          \n",
      ";               PUNCT          \n",
      "michael         PROPN          \n",
      "d.              PROPN          \n",
      "revowand        PROPN          \n",
      "geoffrey        PROPN          \n",
      "e.              PROPN          \n",
      "hinton          PROPN          \n",
      "department      PROPN          \n",
      "computer        PROPN          \n",
      "science         PROPN          \n",
      ",               PUNCT          \n",
      "university      PROPN          \n",
      "toronto         PROPN          \n",
      "toronto         PROPN          \n",
      ",               PUNCT          \n",
      "ontario         PROPN          \n",
      ",               PUNCT          \n",
      "canada          PROPN          \n",
      "ms              PROPN          \n",
      "la              PROPN          \n",
      "abstract        ADJ            \n",
      "deformable      ADJ            \n",
      "models          NOUN           \n",
      "attractive      ADJ            \n",
      "approach        NOUN           \n",
      "recognizing     VERB           \n",
      "nonrigid        ADJ            \n",
      "objects         NOUN           \n",
      "considerable    ADJ            \n",
      "within          ADP            \n",
      "class           NOUN           \n",
      "variability     NOUN           \n",
      ".               PUNCT          \n",
      "however         ADV            \n",
      ",               PUNCT          \n",
      "severe          ADJ            \n",
      "search          NOUN           \n",
      "problems        NOUN           \n",
      "associated      VERB           \n"
     ]
    }
   ],
   "source": [
    "doc=nlp(doc)\n",
    "print(f\"{'Token':<15} {'Part-of-Speech':<15}\")\n",
    "print(\"-\" * 30)\n",
    "for token in doc[:50]: # for the first 50\n",
    "    print(f\"{token.text:<15} {token.pos_:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0d29c",
   "metadata": {
    "papermill": {
     "duration": 0.025365,
     "end_time": "2024-07-31T11:42:15.249389",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.224024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Filtered Tokens Based on POS Tags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dbd915e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:15.307194Z",
     "iopub.status.busy": "2024-07-31T11:42:15.305559Z",
     "iopub.status.idle": "2024-07-31T11:42:15.314729Z",
     "shell.execute_reply": "2024-07-31T11:42:15.313363Z"
    },
    "papermill": {
     "duration": 0.042317,
     "end_time": "2024-07-31T11:42:15.317642",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.275325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30bedc7",
   "metadata": {
    "papermill": {
     "duration": 0.026234,
     "end_time": "2024-07-31T11:42:15.369977",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.343743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The abbreviations  refer to specific POS in NLP:**\n",
    "> * **ADJ**: Adjective \n",
    "> * **VERB**: Verb \n",
    "> * **NOUN**: Noun\n",
    "> * **INTJ**: Interjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e128f34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:15.423505Z",
     "iopub.status.busy": "2024-07-31T11:42:15.422966Z",
     "iopub.status.idle": "2024-07-31T11:42:15.438770Z",
     "shell.execute_reply": "2024-07-31T11:42:15.437230Z"
    },
    "papermill": {
     "duration": 0.046343,
     "end_time": "2024-07-31T11:42:15.441963",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.395620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'sing', 'neural', 'net', 'instantiate', 'deformable', 'model', 'abstract', 'deformable', 'models', 'attractive', 'approach', 'recognizing', 'nonrigid', 'objects', 'considerable', 'class', 'variability', 'severe', 'search', 'problems', 'associated', 'fitting', 'models', 'data', 'show', 'using', 'neural', 'networks', 'provide', 'better', 'starting', 'points', 'search', 'time', 'reduced', 'method', 'demonstrated', 'character', 'recognition', 'task', 'previous', 'work', 'developed', 'approach', 'handwritten', 'character', 'recognition', 'based', 'use', 'deformable', 'models', 'revow', 'obtained', 'good', 'performance', 'method', 'major', 'problem', 'search', 'procedure', 'fitting', 'model', 'image', 'intensive', 'efficient', 'task', 'paper', 'demonstrate', 'possible', 'compile', 'knowledge', 'gained', 'fitting', 'models', 'data', 'obtain', 'starting', 'points', 'reduce', 'search', 'time', 'deformable', 'models', 'digit', 'recognition', 'basic', 'idea', 'using', 'deformable', 'models', 'digit', 'model', 'test', 'image', 'classified', 'finding', 'model', 'generated', 'quality', 'match', 'model', 'test', 'image', 'depends', 'deformation', 'model', 'amount', 'ink', 'attributed', 'noise', 'distance', 'remaining', 'ink', 'deformed', 'model', 'current', 'address', 'department', 'computer', 'science', 'applied', 'mathematics', 'important', 'terms', 'assessing', 'fit', 'prior', 'probability', 'distribution', 'instantiation', 'parameters', 'model', 'penalizes', 'distorted', 'models', 'imaging', 'model', 'characterizes', 'probability', 'distribution', 'possible', 'images', 'given', 'instantiated', 'model', 'l', 'let', 'image', 'model', 'instantiation', 'parameters', 'evidence', 'model', 'given', 'p', 'j', 'ppdz', 'first', 'term', 'instantiation', 'parameters', 'second', 'model', 'likelihood', 'data', 'given', 'instantiated', 'model', 'proportional', 'p', 'assume', 'prior', 'equation', 'correct', 'z', 'dimensions', 'evaluation', 'integral', 'intensive', 'possible', 'make', 'approximation', 'based', 'assumption', 'integrand', 'peaked', 'maximum', 'value', 'case', 'evidence', 'approximated', 'highest', 'peak', 'volume', 'factor', 'measures', 'sharpness', 'peak', 'p', 'taylor', 'expanding', 'second', 'order', 'shown', 'volume', 'factor', 'depends', 'determinant', 'hessian', 'gp', 'taking', 'logs', 'equation', 'defining', 'edej', 'negative', 'log', 'p', 'ejit', 'corresponding', 'term', 'imaging', 'model', 'aim', 'search', 'find', 'minimum', 'e', 'tot', 'edej', 'course', 'total', 'energy', 'many', 'local', 'character', 'recognition', 'task', 'aim', 'find', 'global', 'minimum', 'using', 'continuation', 'method', 'splines', 'transforms', 'imaging', 'models', 'section', 'presents', 'brief', 'overview', 'work', 'using', 'deformable', 'models', 'digit', 'recognition', 'fuller', 'treatment', 'see', 'revow', 'modelled', 'b', 'spline', 'shape', 'determined', 'positions', 'control', 'points', 'object', 'based', 'frame', 'models', 'control', 'points', 'model', 'model', 'generate', 'ideal', 'example', 'digit', 'control', 'points', 'positioned', 'home', 'locations', 'deformed', 'characters', 'produced', 'perturbing', 'control', 'points', 'home', 'locations', 'home', 'locations', 'covariance', 'matrix', 'model', 'adapted', 'order', 'improve', 'performance', 'deformation', 'energy', 'penalizes', 'shape', 'deformations', 'affine', 'transformations', 'translation', 'rotation', 'dilation', 'elongation', 'shear', 'change', 'underlying', 'shape', 'object', 'want', 'deformation', 'achieve', 'giving', 'model', 'object', 'based', 'frame', 'computing', 'relative', 'frame', 'framework', 'used', 'many', 'authors', 'approximation', 'popularized', 'neural', 'net', 'community', 'mackay', 'using', 'neural', 'net', 'instantiate', 'deformable', 'model', 'data', 'used', 'consists', 'binary', 'pixel', 'images', 'segmented', 'handwritten', 'digits', 'general', 'imaging', 'model', 'problem', 'high', 'probability', 'inked', 'pixels', 'close', 'spline', 'lower', 'probabilities', 'achieved', 'spacing', 'number', 'gaussian', 'ink', 'generators', 'contour', 'found', 'useful', 'uniform', 'background', 'noise', 'process', 'area', 'image', 'able', 'account', 'pixels', 'occur', 'generators', 'ink', 'generators', 'background', 'process', 'define', 'mixture', 'model', 'using', 'assumption', 'data', 'point', 'generated', 'given', 'instantiated', 'model', 'p', 'factors', 'product', 'probability', 'density', 'black', 'pixel', 'mixture', 'model', 'recognizing', 'isolated', 'digits', 'model', 'aim', 'search', 'find', 'instantiation', 'parameters', 'minimize', 'tot', 'search', 'starts', 'deformations', 'initial', 'guess', 'affine', 'parameters', 'scales', 'model', 'lie', 'skew', 'rotation', 'small', 'number', 'generators', 'large', 'variance', 'placed', 'spline', 'forming', 'broad', 'smooth', 'high', 'ink', 'probability', 'spline', 'use', 'search', 'procedure', 'similar', 'expectation', 'maximization', 'method', 'fitting', 'unconstrained', 'mixture', 'gaussians', 'constrained', 'lie', 'spline', 'energy', 'term', 'affine', 'transformation', 'recalculated', 'iteration', 'search', 'number', 'generators', 'increased', 'variance', 'decreases', 'according', 'predetermined', 'annealing', 'schedule', 'fitting', 'models', 'particular', 'image', 'wish', 'evaluate', 'models', 'explains', 'data', 'natural', 'measure', 'sum', 'ejit', 'edej', 'volume', 'factor', 'found', 'performance', 'improved', 'including', 'additional', 'terms', 'obtained', 'final', 'fits', 'model', 'image', 'measure', 'penalizes', 'matches', 'beads', 'inked', 'pixels', 'rotation', 'shear', 'elongation', 'affine', 'decide', 'principled', 'way', 'correct', 'weightings', 'terms', 'evaluation', 'function', 'estimated', 'weightings', 'data', 'training', 'simple', 'postprocessing', 'neural', 'network', 'inputs', 'connected', 'output', 'units', 'output', 'units', 'compete', 'using', 'softmax', 'function', 'guarantees', 'form', 'probability', 'distribution', 'summing', 'predicting', 'instantiation', 'parameters', 'search', 'procedure', 'described', 'time', 'consuming', 'given', 'many', 'examples', 'images', 'corresponding', 'instantiation', 'parameters', 'obtained', 'slow', 'method', 'possible', 'train', 'neural', 'predict', 'instantiation', 'parameters', 'novel', 'images', 'predictions', 'provide', 'better', 'starting', 'points', 'search', 'time', 'reduced', 'schedule', 'starts', 'beads', 'increasing', 'beads', 'steps', 'variance', 'decreasing', 'scale', 'set', 'object', 'based', 'frame', 'model', 'unit', 'high', 'previous', 'work', 'previous', 'work', 'hypothesizing', 'instantiation', 'parameters', 'placed', 'broad', 'classes', 'correspondence', 'based', 'search', 'parameter', 'space', 'search', 'correspondence', 'based', 'search', 'idea', 'extract', 'features', 'image', 'identify', 'corresponding', 'features', 'model', 'using', 'sufficient', 'correspondences', 'model', 'determined', 'problem', 'simple', 'detectable', 'image', 'features', 'many', 'possible', 'matches', 'complex', 'features', 'require', 'computation', 'difficult', 'detect', 'shows', 'search', 'space', 'possible', 'correspondences', 'using', 'interpretation', 'tree', 'alternative', 'approach', 'used', 'techniques', 'work', 'parameter', 'space', 'designed', 'detection', 'straight', 'lines', 'images', 'extended', 'cover', 'number', 'geometric', 'shapes', 'conic', 'sections', 'ballard', 'extended', 'approach', 'arbitrary', 'shapes', 'generalized', 'parameter', 'space', 'model', 'divided', 'cells', 'image', 'feature', 'vote', 'added', 'parameter', 'produced', 'feature', 'collecting', 'votes', 'image', 'features', 'search', 'peaks', 'parameter', 'accumulator', 'array', 'attempt', 'verify', 'pose', 'viewed', 'crude', 'way', 'approximating', 'posterior', 'distribution', 'p', 'techniques', 'used', 'problems', 'involving', 'rigid', 'models', 'applicable', 'digit', 'recognition', 'problem', 'space', 'method', 'binning', 'vote', 'collection', 'impractical', 'high', 'dimensional', 'parameter', 'space', 'correspondence', 'based', 'approach', 'lack', 'identified', 'discriminative', 'features', 'strengths', 'techniques', 'ability', 'deal', 'arbitrary', 'scalings', 'rotations', 'translations', 'data', 'tolerance', 'extraneous', 'features', 'required', 'task', 'input', 'data', 'segmented', 'normalized', 'approach', 'use', 'neural', 'network', 'predict', 'instantiation', 'parameters', 'model', 'given', 'input', 'image', 'used', 'similar', 'method', 'simple', 'objects', 'beymer', 'constructed', 'network', 'maps', 'face', 'image', 'parameter', 'space', 'spanning', 'head', 'rotations', 'smile', 'smile', 'dimension', 'method', 'map', 'images', 'instantiation', 'parameters', 'use', 'computer', 'vision', 'determine', 'displacement', 'field', 'pixels', 'novel', 'image', 'relative', 'reference', 'image', 'use', 'field', 'input', 'network', 'step', 'limits', 'use', 'approach', 'images', 'similar', 'correspondence', 'functions', 'instantiating', 'digit', 'models', 'using', 'neural', 'networks', 'network', 'used', 'predict', 'model', 'parameters', 'shown', 'figure', 'binary', 'images', 'normalized', 'give', 'greyscale', 'images', 'fed', 'neural', 'network', 'uses', 'standard', 'layer', 'architecture', 'hidden', 'unit', 'computes', 'weighted', 'sum', 'inputs', 'feeds', 'value', 'sigmoidal', 'nonlinearity', 'using', 'neural', 'net', 'instantiate', 'deformable', 'model', 'cps', 'model', 'cps', 'model', 'model', 'figure', 'prediction', 'network', 'architecture', 'cps', 'stands', 'control', 'points', 'output', 'values', 'weighted', 'linear', 'combination', 'hidden', 'unit', 'activities', 'output', 'biases', 'targets', 'locations', 'control', 'points', 'normalized', 'image', 'found', 'fitting', 'models', 'described', 'section', 'network', 'trained', 'backpropagation', 'minimize', 'squared', 'error', 'using', 'training', 'images', 'validation', 'images', 'digit', 'drawn', 'set', 'cedar', 'database', 'cities', 'states', 'zip', 'codes', 'digits', 'alphabetic', 'characters', 'test', 'sets', 'used', 'obtained', 'data', 'bs', 'test', 'set', 'experimentation', 'chose', 'network', 'hidden', 'units', 'means', 'net', 'weights', 'large', 'number', 'weights', 'important', 'regularize', 'solution', 'obtained', 'network', 'using', 'complexity', 'penalty', 'used', 'weight', 'optimized', 'validation', 'set', 'targets', 'set', 'penalty', 'correct', 'output', 'layer', 'backpropagated', 'output', 'units', 'took', 'epochs', 'train', 'using', 'default', 'conjugate', 'gradient', 'search', 'method', 'xerion', 'simulator', 'possible', 'construct', 'separate', 'networks', 'carry', 'task', 'net', 'described', 'intensify', 'danger', 'overfitting', 'reduced', 'giving', 'network', 'common', 'pool', 'hidden', 'units', 'use', 'decides', 'appropriate', 'prediction', 'net', 'described', 'trivial', 'network', 'consisted', 'output', 'biases', 'trained', 'network', 'learns', 'average', 'value', 'control', 'point', 'locations', 'validation', 'set', 'squared', 'error', 'prediction', 'net', 'times', 'smaller', 'trivial', 'net', 'encouraging', 'acid', 'test', 'compare', 'performance', 'elastic', 'models', 'settled', 'predicted', 'positions', 'using', 'shortened', 'annealing', 'schedule', 'predictions', 'good', 'short', 'amount', 'settling', 'required', 'made', 'available', 'office', 'advanced', 'technology', 'xerion', 'designed', 'implemented', 'drew', 'camp', 'tony', 'comparision', 'initial', 'instantiations', 'due', 'prediction', 'net', 'trivial', 'net', 'image', 'notice', 'model', 'prediction', 'net', 'closer', 'data', 'digit', 'models', 'mayor', 'affected', 'input', 'data', 'example', 'predictions', 'nets', 'seem', 'prediction', 'net', 'puts', 'model', 'data', 'feedforward', 'predicts', 'position', 'control', 'points', 'normalized', 'image', 'inverting', 'normalization', 'process', 'positions', 'control', 'points', 'normalized', 'image', 'determined', 'model', 'corresponding', 'image', 'control', 'point', 'locations', 'determined', 'running', 'part', 'iteration', 'search', 'procedure', 'experiments', 'conducted', 'number', 'shortened', 'annealing', 'schedules', 'data', 'obtained', 'settling', 'part', 'training', 'data', 'used', 'train', 'postprocessing', 'net', 'performance', 'evaluated', 'test', 'set', 'full', 'annealing', 'schedule', 'stages', 'shortened', 'annealing', 'schedules', 'settling', 'iterations', 'final', 'variance', 'iteration', 'full', 'annealing', 'schedule', 'results', 'test', 'set', 'shown', 'table', 'general', 'trends', 'performance', 'obtained', 'using', 'prediction', 'net', 'trivial', 'net', 'annealing', 'schedules', 'lead', 'better', 'performance', 'comparison', 'schedules', 'table', 'indicates', 'performance', 'prediction', 'net', 'schedule', 'combination', 'similar', 'obtained', 'full', 'annealing', 'schedule', 'factor', 'results', 'full', 'schedule', 'identical', 'results', 'obtained', 'default', 'initialization', 'described', 'section', 'figure', 'compares', 'outputs', 'prediction', 'trivial', 'nets', 'particular', 'example', 'judging', 'weight', 'using', 'neural', 'net', 'instantiate', 'deformable', 'model', 'schedule', 'number', 'trivial', 'net', 'prediction', 'net', 'average', 'time', 'required', 'settle', 'model', 'table', 'errors', 'internal', 'test', 'set', 'examples', 'different', 'annealing', 'schedules', 'timing', 'trials', 'carried', 'r-', 'machine', 'vectors', 'activity', 'patterns', 'hidden', 'units', 'seem', 'units', 'specialized', 'particular', 'digit', 'class', 'run', 'test', 'set', 'using', 'schedule', 'gave', 'error', 'rate', 'similar', 'errors', 'obtained', 'using', 'full', 'annealing', 'box', 'initialization', 'comparison', 'errors', 'made', 'runs', 'shows', 'errors', 'common', 'sets', 'suggests', 'sensible', 'reject', 'cases', 'methods', 'agree', 'discussion', 'prediction', 'net', 'used', 'viewed', 'interpolation', 'scheme', 'control', 'point', 'position', 'space', 'z', 'predicted', 'position', 'control', 'point', 'space', 'contribution', 'due', 'biases', 'ai', 'activity', 'hidden', 'unit', 'control', 'point', 'position', 'space', 'hidden', 'units', 'output', 'dimensions', 'particular', 'image', 'infinite', 'number', 'ways', 'make', 'equation', 'hold', 'network', 'find', 'solutions', 'ai', 'vary', 'image', 'perturbed', 'nets', 'described', 'output', 'set', 'instantiation', 'parameters', 'given', 'model', 'preferable', 'able', 'represent', 'number', 'guesses', 'model', 'instantiation', 'parameters', 'way', 'train', 'network', 'multiple', 'sets', 'output', 'parameters', 'mixture', 'experts', 'architecture', 'jacobs', 'ai', 'outputs', 'interpreted', 'mixture', 'distribution', 'control', 'point', 'position', 'space', 'conditioned', 'input', 'image', 'approach', 'providing', 'information', 'posterior', 'distribution', 'described', 'p', 'approximated', 'using', 'fixed', 'set', 'basis', 'functions', 'weighting', 'depends', 'input', 'image', 'i.', 'strategies', 'descriped', 'predict', 'instantiation', 'parameters', 'parameter', 'space', 'possible', 'use', 'neural', 'networks', 'hypothesize', 'correspondences', 'inked', 'position', 'spline', 'given', 'local', 'window', 'context', 'image', 'sufficient', 'matches', 'possible', 'compute', 'parameters', 'model', 'conducted', 'preliminary', 'experiments', 'method', 'indicate', 'good', 'performance', 'achieved', 'correspondence', 'prediction', 'task', 'shown', 'obtain', 'significant', 'speedup', 'using', 'prediction', 'net', 'schemes', 'outlined', 'allow', 'multimodal', 'predictions', 'instantiation', 'parameter', 'space', 'improve', 'performance', 'deserve', 'investigation', 'interested', 'improving', 'performance', 'prediction', 'net', 'example', 'outputting', 'confidence', 'measure', 'used', 'adjust', 'length', 'elastic', 'models', 'search', 'believe', 'using', 'machine', 'learning', 'techniques', 'neural', 'networks', 'help', 'reduce', 'amount', 'search', 'required', 'fit', 'complex', 'models', 'data', 'useful', 'many', 'problems', 'acknowledgements', 'research', 'funded', 'apple', 'information', 'research', 'centre', 'thank', 'rich', 'zemel', 'helpful', 'discussions', 'advanced', 'research', 'references', 'ballard', 'generalizing', 'detect', 'arbitrary', 'shapes', 'pattern', 'recognition', 'example', 'based', 'image', 'analysis', 'synthesis', 'memo', 'laboratory', 'hands', 'pattern', 'theoretic', 'study', 'biological', 'shapes', 'object', 'computer', 'cambridge', 'revow', 'adaptive', 'elastic', 'models', 'hand', 'printed', 'character', 'recognition', 'editors', 'advances', 'neural', 'information', 'processing', 'systems', 'revow', 'combinining', 'methods', 'recognizing', 'hand', 'printed', 'digits', 'aleksander', 'editors', 'artificial', 'neural', 'networks', 'elsevier', 'science', 'publishers', 'hunt', 'performance', 'relationship', 'statistical', 'signal', 'detection', 'theory', 'computer', 'vision', 'graphics', 'image', 'processing', 'local', 'experts', 'neural', 'computation', 'mackay', 'neural', 'computation', 'using', 'mixtures', 'deformable', 'models', 'capture', 'variations', 'hand', 'printed', 'digits', 'editor', 'proceedings', 'third', 'international', 'workshop', 'frontiers', 'handwriting', 'recognition', 'pages', 'combining', 'deformable', 'models', 'neural', 'networks', 'handprinted', 'recognition', 'phd', 'thesis', 'dept', 'computer', 'discovering', 'viewpoint', 'invariant', 'relationships', 'characterize', 'objects', 'editors', 'advances', 'neural', 'information', 'processing', 'systems', 'pages', 'publishers'] "
     ]
    }
   ],
   "source": [
    "\n",
    "allowed_pos=['ADJ','VERB','NOUN','INTJ']\n",
    "tokens_1=[]\n",
    "\n",
    "for token in doc:\n",
    "    if  token.text in punctuation:\n",
    "        continue\n",
    "    elif token.pos_ in allowed_pos:\n",
    "        tokens_1.append(token.text)\n",
    "        \n",
    "print(tokens_1,end=\" \")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ec905",
   "metadata": {
    "papermill": {
     "duration": 0.025885,
     "end_time": "2024-07-31T11:42:15.495040",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.469155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Word Frequency Count of Filtered Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38a82e31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:15.550392Z",
     "iopub.status.busy": "2024-07-31T11:42:15.549214Z",
     "iopub.status.idle": "2024-07-31T11:42:15.559363Z",
     "shell.execute_reply": "2024-07-31T11:42:15.557614Z"
    },
    "papermill": {
     "duration": 0.04141,
     "end_time": "2024-07-31T11:42:15.562331",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.520921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'model': 45, 'image': 27, 'net': 23, 'using': 23, 'models': 22, 'search': 20, 'neural': 19, 'parameters': 17, 'data': 16, 'network': 15, 'instantiation': 14, 'control': 14, 'prediction': 14, 'space': 13, 'performance': 12, 'set': 12, 'deformable': 11, 'points': 11, 'images': 11, 'used': 11, 'method': 10, 'recognition': 10, 'obtained': 10, 'annealing': 10, 'schedule': 10, 'output': 10, 'based': 9, 'possible': 9, 'digit': 9, 'test': 9, 'number': 9, 'parameter': 9, 'approach': 8, 'use': 8, 'given': 8, 'units': 8, 'networks': 7, 'p': 7, 'point': 7, 'described': 7, 'features': 7, 'hidden': 7, 'fitting': 6, 'task': 6, 'probability': 6, 'distribution': 6, 'spline': 6, 'locations': 6, 'input': 6, 'trivial': 6, 'position': 6, 'time': 5, 'work': 5, 'ink': 5, 'computer': 5, 'many': 5, 'object': 5, 'example': 5, 'digits': 5, 'generators': 5, 'mixture': 5, 'similar': 5, 'correspondence': 5, 'normalized': 5, 'schedules': 5, 'full': 5, 'instantiate': 4, 'character': 4, 'revow': 4, 'problem': 4, 'procedure': 4, 'imaging': 4, 'factor': 4, 'shown': 4, 'corresponding': 4, 'find': 4, 'determined': 4, 'frame': 4, 'affine': 4, 'high': 4, 'pixels': 4, 'variance': 4, 'particular': 4, 'train': 4, 'predict': 4, 'predictions': 4, 'unit': 4, 'techniques': 4, 'shapes': 4, 'required': 4, 'errors': 4, 'information': 4, 'recognizing': 3, 'objects': 3, 'problems': 3, 'better': 3, 'starting': 3, 'reduced': 3, 'previous': 3, 'good': 3, 'depends': 3, 'deformation': 3, 'amount': 3, 'terms': 3, 'penalizes': 3, 'instantiated': 3, 'term': 3, 'equation': 3, 'correct': 3, 'value': 3, 'volume': 3, 'edej': 3, 'aim': 3, 'energy': 3, 'local': 3, 'section': 3, 'shape': 3, 'positions': 3, 'home': 3, 'rotation': 3, 'inked': 3, 'found': 3, 'process': 3, 'iteration': 3, 'measure': 3, 'matches': 3, 'beads': 3, 'way': 3, 'training': 3, 'simple': 3, 'correspondences': 3, 'computation': 3, 'arbitrary': 3, 'figure': 3, 'architecture': 3, 'cps': 3, 'biases': 3, 'error': 3, 'validation': 3, 'sets': 3, 'elastic': 3, 'shortened': 3, 'settling': 3, 'nets': 3, 'results': 3, 'table': 3, 'ai': 3, 'research': 3, 'hand': 3, 'printed': 3, 'editors': 3, 'processing': 3, 'class': 2, 'provide': 2, 'handwritten': 2, 'intensive': 2, 'obtain': 2, 'reduce': 2, 'idea': 2, 'generated': 2, 'noise': 2, 'deformed': 2, 'science': 2, 'important': 2, 'fit': 2, 'prior': 2, 'evidence': 2, 'second': 2, 'z': 2, 'dimensions': 2, 'evaluation': 2, 'make': 2, 'approximation': 2, 'assumption': 2, 'approximated': 2, 'peak': 2, 'order': 2, 'ejit': 2, 'minimum': 2, 'tot': 2, 'characters': 2, 'produced': 2, 'improve': 2, 'deformations': 2, 'elongation': 2, 'shear': 2, 'giving': 2, 'relative': 2, 'mackay': 2, 'binary': 2, 'pixel': 2, 'segmented': 2, 'general': 2, 'achieved': 2, 'useful': 2, 'background': 2, 'able': 2, 'minimize': 2, 'starts': 2, 'initial': 2, 'lie': 2, 'large': 2, 'placed': 2, 'broad': 2, 'sum': 2, 'final': 2, 'weightings': 2, 'function': 2, 'postprocessing': 2, 'inputs': 2, 'examples': 2, 'novel': 2, 'sufficient': 2, 'complex': 2, 'detect': 2, 'shows': 2, 'designed': 2, 'detection': 2, 'extended': 2, 'ballard': 2, 'feature': 2, 'vote': 2, 'viewed': 2, 'posterior': 2, 'rotations': 2, 'smile': 2, 'vision': 2, 'field': 2, 'functions': 2, 'layer': 2, 'weighted': 2, 'combination': 2, 'targets': 2, 'trained': 2, 'squared': 2, 'weights': 2, 'penalty': 2, 'weight': 2, 'default': 2, 'xerion': 2, 'common': 2, 'average': 2, 'predicted': 2, 'made': 2, 'advanced': 2, 'due': 2, 'seem': 2, 'part': 2, 'experiments': 2, 'conducted': 2, 'comparison': 2, 'initialization': 2, 'outputs': 2, 'machine': 2, 'activity': 2, 'methods': 2, 'experts': 2, 'pattern': 2, 'advances': 2, 'systems': 2, 'publishers': 2, 'pages': 2, 'u': 1, 'sing': 1, 'abstract': 1, 'attractive': 1, 'nonrigid': 1, 'considerable': 1, 'variability': 1, 'severe': 1, 'associated': 1, 'show': 1, 'demonstrated': 1, 'developed': 1, 'major': 1, 'efficient': 1, 'paper': 1, 'demonstrate': 1, 'compile': 1, 'knowledge': 1, 'gained': 1, 'basic': 1, 'classified': 1, 'finding': 1, 'quality': 1, 'match': 1, 'attributed': 1, 'distance': 1, 'remaining': 1, 'current': 1, 'address': 1, 'department': 1, 'applied': 1, 'mathematics': 1, 'assessing': 1, 'distorted': 1, 'characterizes': 1, 'l': 1, 'let': 1, 'j': 1, 'ppdz': 1, 'first': 1, 'likelihood': 1, 'proportional': 1, 'assume': 1, 'integral': 1, 'integrand': 1, 'peaked': 1, 'maximum': 1, 'case': 1, 'highest': 1, 'measures': 1, 'sharpness': 1, 'taylor': 1, 'expanding': 1, 'determinant': 1, 'hessian': 1, 'gp': 1, 'taking': 1, 'logs': 1, 'defining': 1, 'negative': 1, 'log': 1, 'e': 1, 'course': 1, 'total': 1, 'global': 1, 'continuation': 1, 'splines': 1, 'transforms': 1, 'presents': 1, 'brief': 1, 'overview': 1, 'fuller': 1, 'treatment': 1, 'see': 1, 'modelled': 1, 'b': 1, 'generate': 1, 'ideal': 1, 'positioned': 1, 'perturbing': 1, 'covariance': 1, 'matrix': 1, 'adapted': 1, 'transformations': 1, 'translation': 1, 'dilation': 1, 'change': 1, 'underlying': 1, 'want': 1, 'achieve': 1, 'computing': 1, 'framework': 1, 'authors': 1, 'popularized': 1, 'community': 1, 'consists': 1, 'close': 1, 'lower': 1, 'probabilities': 1, 'spacing': 1, 'gaussian': 1, 'contour': 1, 'uniform': 1, 'area': 1, 'account': 1, 'occur': 1, 'define': 1, 'factors': 1, 'product': 1, 'density': 1, 'black': 1, 'isolated': 1, 'guess': 1, 'scales': 1, 'skew': 1, 'small': 1, 'forming': 1, 'smooth': 1, 'expectation': 1, 'maximization': 1, 'unconstrained': 1, 'gaussians': 1, 'constrained': 1, 'transformation': 1, 'recalculated': 1, 'increased': 1, 'decreases': 1, 'according': 1, 'predetermined': 1, 'wish': 1, 'evaluate': 1, 'explains': 1, 'natural': 1, 'improved': 1, 'including': 1, 'additional': 1, 'fits': 1, 'decide': 1, 'principled': 1, 'estimated': 1, 'connected': 1, 'compete': 1, 'softmax': 1, 'guarantees': 1, 'form': 1, 'summing': 1, 'predicting': 1, 'consuming': 1, 'slow': 1, 'increasing': 1, 'steps': 1, 'decreasing': 1, 'scale': 1, 'hypothesizing': 1, 'classes': 1, 'extract': 1, 'identify': 1, 'detectable': 1, 'require': 1, 'difficult': 1, 'interpretation': 1, 'tree': 1, 'alternative': 1, 'straight': 1, 'lines': 1, 'cover': 1, 'geometric': 1, 'conic': 1, 'sections': 1, 'generalized': 1, 'divided': 1, 'cells': 1, 'added': 1, 'collecting': 1, 'votes': 1, 'peaks': 1, 'accumulator': 1, 'array': 1, 'attempt': 1, 'verify': 1, 'pose': 1, 'crude': 1, 'approximating': 1, 'involving': 1, 'rigid': 1, 'applicable': 1, 'binning': 1, 'collection': 1, 'impractical': 1, 'dimensional': 1, 'lack': 1, 'identified': 1, 'discriminative': 1, 'strengths': 1, 'ability': 1, 'deal': 1, 'scalings': 1, 'translations': 1, 'tolerance': 1, 'extraneous': 1, 'beymer': 1, 'constructed': 1, 'maps': 1, 'face': 1, 'spanning': 1, 'head': 1, 'dimension': 1, 'map': 1, 'determine': 1, 'displacement': 1, 'reference': 1, 'step': 1, 'limits': 1, 'instantiating': 1, 'give': 1, 'greyscale': 1, 'fed': 1, 'uses': 1, 'standard': 1, 'computes': 1, 'feeds': 1, 'sigmoidal': 1, 'nonlinearity': 1, 'stands': 1, 'values': 1, 'linear': 1, 'activities': 1, 'backpropagation': 1, 'drawn': 1, 'cedar': 1, 'database': 1, 'cities': 1, 'states': 1, 'zip': 1, 'codes': 1, 'alphabetic': 1, 'bs': 1, 'experimentation': 1, 'chose': 1, 'means': 1, 'regularize': 1, 'solution': 1, 'complexity': 1, 'optimized': 1, 'backpropagated': 1, 'took': 1, 'epochs': 1, 'conjugate': 1, 'gradient': 1, 'simulator': 1, 'construct': 1, 'separate': 1, 'carry': 1, 'intensify': 1, 'danger': 1, 'overfitting': 1, 'pool': 1, 'decides': 1, 'appropriate': 1, 'consisted': 1, 'learns': 1, 'times': 1, 'smaller': 1, 'encouraging': 1, 'acid': 1, 'compare': 1, 'settled': 1, 'short': 1, 'available': 1, 'office': 1, 'technology': 1, 'implemented': 1, 'drew': 1, 'camp': 1, 'tony': 1, 'comparision': 1, 'instantiations': 1, 'notice': 1, 'closer': 1, 'mayor': 1, 'affected': 1, 'puts': 1, 'feedforward': 1, 'predicts': 1, 'inverting': 1, 'normalization': 1, 'running': 1, 'evaluated': 1, 'stages': 1, 'iterations': 1, 'trends': 1, 'lead': 1, 'indicates': 1, 'identical': 1, 'compares': 1, 'judging': 1, 'settle': 1, 'internal': 1, 'different': 1, 'timing': 1, 'trials': 1, 'carried': 1, 'r-': 1, 'vectors': 1, 'patterns': 1, 'specialized': 1, 'run': 1, 'gave': 1, 'rate': 1, 'box': 1, 'runs': 1, 'suggests': 1, 'sensible': 1, 'reject': 1, 'cases': 1, 'agree': 1, 'discussion': 1, 'interpolation': 1, 'scheme': 1, 'contribution': 1, 'infinite': 1, 'ways': 1, 'hold': 1, 'solutions': 1, 'vary': 1, 'perturbed': 1, 'preferable': 1, 'represent': 1, 'guesses': 1, 'multiple': 1, 'jacobs': 1, 'interpreted': 1, 'conditioned': 1, 'providing': 1, 'fixed': 1, 'basis': 1, 'weighting': 1, 'i.': 1, 'strategies': 1, 'descriped': 1, 'hypothesize': 1, 'window': 1, 'context': 1, 'compute': 1, 'preliminary': 1, 'indicate': 1, 'significant': 1, 'speedup': 1, 'schemes': 1, 'outlined': 1, 'allow': 1, 'multimodal': 1, 'deserve': 1, 'investigation': 1, 'interested': 1, 'improving': 1, 'outputting': 1, 'confidence': 1, 'adjust': 1, 'length': 1, 'believe': 1, 'learning': 1, 'help': 1, 'acknowledgements': 1, 'funded': 1, 'apple': 1, 'centre': 1, 'thank': 1, 'rich': 1, 'zemel': 1, 'helpful': 1, 'discussions': 1, 'references': 1, 'generalizing': 1, 'analysis': 1, 'synthesis': 1, 'memo': 1, 'laboratory': 1, 'hands': 1, 'theoretic': 1, 'study': 1, 'biological': 1, 'cambridge': 1, 'adaptive': 1, 'combinining': 1, 'aleksander': 1, 'artificial': 1, 'elsevier': 1, 'hunt': 1, 'relationship': 1, 'statistical': 1, 'signal': 1, 'theory': 1, 'graphics': 1, 'mixtures': 1, 'capture': 1, 'variations': 1, 'editor': 1, 'proceedings': 1, 'third': 1, 'international': 1, 'workshop': 1, 'frontiers': 1, 'handwriting': 1, 'combining': 1, 'handprinted': 1, 'phd': 1, 'thesis': 1, 'dept': 1, 'discovering': 1, 'viewpoint': 1, 'invariant': 1, 'relationships': 1, 'characterize': 1})\t"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freq=Counter(tokens_1)\n",
    "print(word_freq,end=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979127e8",
   "metadata": {
    "papermill": {
     "duration": 0.025927,
     "end_time": "2024-07-31T11:42:15.614599",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.588672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract Sentences from the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61798e60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:15.736000Z",
     "iopub.status.busy": "2024-07-31T11:42:15.735498Z",
     "iopub.status.idle": "2024-07-31T11:42:16.154531Z",
     "shell.execute_reply": "2024-07-31T11:42:16.153041Z"
    },
    "papermill": {
     "duration": 0.452434,
     "end_time": "2024-07-31T11:42:16.157218",
     "exception": false,
     "start_time": "2024-07-31T11:42:15.704784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=nlp(doc)\n",
    "sent_token=[sent.text for sent in doc.sents]\n",
    "len(sent_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802cc0f8",
   "metadata": {
    "papermill": {
     "duration": 0.026617,
     "end_time": "2024-07-31T11:42:16.210418",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.183801",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentence Scores Based on Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8cfb4ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:16.268790Z",
     "iopub.status.busy": "2024-07-31T11:42:16.268266Z",
     "iopub.status.idle": "2024-07-31T11:42:16.278384Z",
     "shell.execute_reply": "2024-07-31T11:42:16.276945Z"
    },
    "papermill": {
     "duration": 0.046031,
     "end_time": "2024-07-31T11:42:16.283688",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.237657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u sing neural net instantiate deformable model christopher k. i. williams ; michael d. revowand geoffrey e. hinton department computer science , university toronto toronto , ontario , canada ms la abstract deformable models attractive approach recognizing nonrigid objects considerable within class variability .': 167, 'however , severe search problems associated fitting models data .': 69, 'show using neural networks provide better starting points , search time significantly reduced .': 97, 'method demonstrated character recognition task .': 31, 'previous work developed approach handwritten character recognition based use deformable models ( hinton , williams revow , ; revow , williams hinton , ) .': 91, 'obtained good performance method , major problem search procedure fitting model image computationally intensive , efficient algorithm task .': 151, \"paper demonstrate possible `` compile '' knowledge gained fitting models data obtain better starting points significantly reduce search time .\": 104, 'deformable models digit recognition basic idea using deformable models digit recognition digit model , test image classified finding model likely generated .': 269, 'quality match model test image depends deformation model , amount ink attributed noise distance remaining ink deformed model . ?': 199, 'current address : department computer science applied mathematics , aston university , birmingham b et , uk .': 13, 'christopher k. t. williams , michael d. revow , geoffrey e. hinton formally , two important terms assessing fit prior probability distribution instantiation parameters model ( penalizes distorted models ) , imaging model characterizes probability distribution possible images given instantiated model l .': 267, 'let image , model z instantiation parameters .': 106, 'evidence model given p = j ppdz first term integrand prior instantiation parameters second imaging model e. , likelihood data given instantiated model .': 226, 'p directly proportional p , assume uniform prior digit .': 28, 'equation formally correct , z dimensions evaluation integral computationally intensive .': 15, 'however , often possible make approximation based assumption integrand strongly peaked around maximum value z* .': 30, 'case , evidence approximated highest peak integrand times volume factor ~ , measures sharpness peak .': 21, 'p ~ pp~ taylor expanding around z* second order shown volume factor depends determinant hessian gp .': 30, 'taking logs equation , defining edej negative log p , ejit corresponding term imaging model , aim search find minimum e tot = edej + ejit .': 113, 'course total energy many local minima ; character recognition task aim find global minimum using continuation method . .': 77, 'splines , affine transforms imaging models section presents brief overview work using deformable models digit recognition .': 118, 'fuller treatment , see revow , williams hinton .': 7, 'digit modelled cubic b-spline whose shape determined positions control points object-based frame .': 49, 'models eight control points , except one model three , seven model five .': 137, \"generate ideal example digit control points positioned `` home '' locations .\": 51, 'deformed characters produced perturbing control points away home locations .': 41, 'home locations covariance matrix model adapted order improve performance .': 73, 'deformation energy penalizes shape deformations .': 14, 'affine transformations , e. , translation , rotation , dilation , elongation , shear , change underlying shape object want deformation energy invariant .': 32, \"achieve giving model `` object-based frame '' computing deformation energy relative frame .\": 65, 'lthis framework used many authors , g. grenander et al .': 18, 'gaussian approximation popularized neural net community mackay .': 49, 'using neural net instantiate deformable model data used consists binary-pixel images segmented handwritten digits .': 173, 'general flavour imaging model problem high probability inked pixels close spline , lower probabilities away .': 81, \"achieved spacing number gaussian `` ink generators '' uniformly along contour ; found also useful uniform background noise process area image able account pixels occur far away generators .\": 78, 'ink generators background process define mixture model .': 66, 'using assumption data point generated independently given instantiated model , p factors product probability density black pixel mixture model .': 175, '.': 0, 'recognizing isolated digits model , aim search find instantiation parameters minimize e tot .': 117, 'search starts zero deformations initial guess affine parameters scales model lie data zero skew rotation .': 116, 'small number generators large variance placed along spline , forming broad , smooth ridge high ink-probability along spline .': 43, 'use search procedure similar expectation maximization method fitting unconstrained mixture gaussians , except gaussians constrained lie spline deformation energy term affine transformation must recalculated iteration .': 90, \"search number generators gradually increased variance decreases according predetermined `` annealing '' schedule .\": 62, \"fitting models particular image , wish evaluate models best `` explains '' data .\": 100, 'natural measure sum ejit , edej volume factor .': 18, 'however , found performance improved including four additional terms easily obtained final fits model image .': 106, 'measure penalizes matches beads far inked pixels , rotation , shear elongation affine transform .': 30, 'hard decide principled way correct weightings terms evaluation function .': 17, 'estimated weightings data training simple postprocessing neural network .': 61, 'inputs connected directly ten output units .': 21, \"output units compete using `` softmax '' function guarantees form probability distribution , summing one .\": 60, 'predicting instantiation parameters search procedure described time consuming .': 69, 'however , given many examples images corresponding instantiation parameters obtained slow method , possible train neural network predict instantiation parameters novel images .': 177, 'predictions provide better starting points , search time reduced .': 51, 'schedule starts beads increasing beads six steps , variance decreasing . . .': 25, 'scale set object-based frame model unit high .': 70, 'christopher k. i. williams , michael d. revow , geoffrey e. hinton previous work previous work hypothesizing instantiation parameters placed two broad classes , correspondence based search parameter space search .': 134, 'correspondence based search , idea extract features image identify corresponding features model .': 128, 'using sufficient correspondences instantiation parameters model determined .': 108, 'problem simple , easily detectable image features many possible matches , complex features require computation difficult detect .': 75, 'grimson shows search space possible correspondences using interpretation tree .': 72, 'alternative approach , used hough transform techniques , directly work parameter space .': 51, 'hough transform originally designed detection straight lines images , extended cover number geometric shapes , notably conic sections .': 36, 'ballard extended approach arbitrary shapes generalized hough transform .': 20, 'parameter space model divided cells , image feature vote added parameter space bin could produced feature .': 127, 'collecting votes image features search peaks parameter space accumulator array , attempt verify pose .': 84, 'hough transform viewed crude way approximating logarithm posterior distribution p .': 22, 'however , two techniques used problems involving rigid models , readily applicable digit recognition problem .': 66, 'hough space method , binning vote collection impractical high dimensional parameter space , correspondence based approach lack easily identified highly discriminative features .': 87, 'strengths two techniques , namely ability deal arbitrary scalings , rotations translations data , tolerance extraneous features , really required task input data fairly well segmented normalized .': 78, 'approach use neural network predict instantiation parameters model , given input image .': 171, 'zemel hinton used similar method simple -d objects , recently , beymer et al constructed network maps face image -d parameter space spanning head rotations smile/no-smile dimension .': 106, 'however , method directly map images instantiation parameters ; use computer vision correspondence algorithm determine displacement field pixels novel image relative reference image , use field input network .': 171, 'step limits use approach images sufficiently similar correspondence algorithm functions well . .': 41, 'instantiating digit models using neural networks network used predict model instantiation parameters shown figure .': 194, 'binary images normalized give x -bit greyscale images fed neural network .': 66, 'network uses standard three-layer architecture ; hidden unit computes weighted sum inputs , feeds value sigmoidal nonlinearity u = / .': 45, 'using neural net instantiate deformable model cps model cps model cps model figure : prediction network architecture .': 304, \"`` cps '' stands control points .\": 29, 'output values weighted linear combination hidden unit activities plus output biases .': 41, 'targets locations control points normalized image , found fitting models described section ..': 106, 'network trained backpropagation minimize squared error , using training images validation images digit drawn br set cedar cdrom database cities , states , zip codes , digits , alphabetic characters .': 112, 'two test sets used ; one obtained data br dataset , bs test set .': 71, 'experimentation chose network twenty hidden units , means net , weights .': 58, 'large number weights important regularize solution obtained network using complexity penalty ; used weight optimized validation set .': 97, 'targets set penalty al : j correct digit output layer ; nothing backpropagated output units .': 60, 'net took epochs train using default conjugate gradient search method xerion neural network simulator .': 123, 'would possible construct ten separate networks carry task net described , would intensify danger overfitting , reduced giving network common pool hidden units use decides appropriate .': 106, 'wj comparison prediction net described , trivial network consisted output biases trained ; network simply learns average value control point locations .': 131, 'validation set squared error prediction net three times smaller trivial net .': 88, 'although encouraging , acid test compare performance elastic models settled predicted positions using shortened annealing schedule ;': 101, 'predictions good , short amount settling required .': 18, 'made available unites states postal service office advanced technology .': 8, 'xerion designed implemented drew van camp , tony plate geoffrey hinton university toronto .': 8, 'christopher k. i. williams , michael d. revow , geoffrey e. hinton figure : comparision initial instantiations due prediction net trivial net image .': 107, 'notice two model prediction net much closer data .': 100, 'digit models mayor may greatly affected input data ; example , predictions nets seem essentially zero , seven prediction net puts model nearer data .': 168, 'feedforward net predicts position control points normalized image .': 88, 'inverting normalization process , positions control points un-normalized image determined .': 64, 'model deformation affine transformation corresponding image control point locations determined running part one iteration search procedure .': 145, 'experiments conducted number shortened annealing schedules ; one , data obtained settling part training data used train postprocessing net .': 121, 'performance evaluated br test set .': 34, 'full annealing schedule six stages .': 26, 'shortened annealing schedules : .': 18, 'settling .': 3, 'two iterations final variance . .': 7, 'one iteration .': 3, 'two . .': 0, 'full annealing schedule results br test set shown table .': 56, 'general trends performance obtained using prediction net consistently better trivial net , longer annealing schedules lead better performance .': 148, 'comparison schedules table indicates performance prediction net/schedule combination similar obtained full annealing schedule , factor two faster .': 83, \"results full schedule almost identical results obtained default `` box '' initialization described section .. figure compares outputs prediction trivial nets particular example .\": 85, 'judging weight using neural net instantiate deformable model schedule number trivial net prediction net average time required settle one model . . .': 270, 'table :': 3, 'errors internal test set examples different annealing schedules .': 44, 'timing trials carried r- machine .': 6, 'vectors activity patterns hidden units , seem units specialized particular digit class .': 45, 'run bs test set using schedule gave error rate .': 61, '% , similar errors obtained using full annealing schedule box initialization .': 70, 'comparison errors made two runs shows errors common two sets .': 20, 'suggests would sensible reject cases two methods agree .': 7, 'discussion prediction net used viewed interpolation scheme control point position space digit z = zo + : aizi , z predicted position control point space , zo contribution due biases , ai activity hidden unit zi location control point position space .': 210, 'hidden units output dimensions , particular image infinite number ways make equation hold exactly .': 75, \"however , network tend find solutions ai 's vary smoothly image perturbed .\": 52, 'nets described output one set instantiation parameters given model .': 116, \"however , may preferable able represent number guesses model instantiation parameters ; one way train network multiple sets output parameters , `` mixture experts '' architecture jacobs et ai .\": 157, 'outputs interpreted mixture distribution control point position space , conditioned input image .': 88, 'another approach providing information posterior distribution described , p approximated using fixed set basis functions whose weighting depends input image i. strategies descriped directly predict instantiation parameters parameter space .': 173, \"also possible use neural networks hypothesize correspondences , e. predict inked pixel 's position spline given local window context image .\": 108, 'sufficient matches possible compute instantiation parameters model .': 91, 'conducted preliminary experiments method , indicate good performance achieved correspondence prediction task .': 58, 'christopher k. i. williams , michael d. revow , geoffrey e. hinton shown obtain significant speedup using prediction net .': 73, 'schemes outlined allow multimodal predictions instantiation parameter space may improve performance deserve investigation .': 60, \"also interested improving performance prediction net , example outputting confidence measure could used adjust length elastic models ' search appropriately .\": 119, 'believe using machine learning techniques like neural networks help reduce amount search required fit complex models data may useful many problems .': 139, 'acknowledgements research funded apple ontario information technology research centre .': 15, 'thank allan jepson , richard durbin , rich zemel , peter dayan , rob tibshirani yann le cun helpful discussions .': 5, 'geoffrey hinton noranda fellow canadian institute advanced research .': 5, 'references ballard , d. h. .': 3, 'generalizing hough transfrom detect arbitrary shapes .': 10, 'pattern recognition , : - .': 12, 'beymer , d. , shashua , a. , poggio , . .': 1, 'example based image analysis synthesis .': 43, 'ai memo , ai laboratory , mit .': 8, 'grenander , u. , chow , y. , keenan , d. m. .': 0, 'hands : pattern theoretic study biological shapes .': 10, 'springer-verlag .': 0, 'grimson , w. e. .': 0, 'object recognition computer .': 20, 'mit press , cambridge , .': 1, 'hinton , g. e. , williams , c. k . .': 0, ', revow , m. d. .': 4, 'adaptive elastic models hand-printed character recognition .': 40, 'moody , j. e. , hanson , s. j. , lippmann , r. p. , editors , advances neural information processing systems .': 33, 'morgan kauffmann .': 0, 'combinining two methods recognizing hand-printed digits .': 11, 'aleksander , .': 1, 'taylor , j. , editors , artificial neural networks .': 31, 'elsevier science publishers .': 5, 'hunt , d. j. , nolte , l. w. , ruedger , w .': 1, 'h. .': 0, 'performance hough transform relationship statistical signal detection theory .': 18, 'computer vision , graphics image processing , : - . jacobs , r. a. , jordan , . .': 39, ', nowlan , s. j. , hinton , g. e. .': 0, 'adaptive mixtures local experts .': 7, 'neural computation , .': 22, 'mackay , d. j. c. .': 2, 'bayesian interpolation .': 1, 'neural computation , : - .': 22, 'revow , m. d. , williams , c. k . .': 4, ', hinton , g. e. .': 0, 'using mixtures deformable models capture variations hand printed digits .': 70, 'srihari , s. , editor , proceedings third international workshop frontiers handwriting recognition , pages - , buffalo , new york , usa .': 19, 'williams , c. k. .': 0, 'combining deformable models neural networks handprinted digit recognition .': 80, 'phd thesis , dept .': 3, 'computer science , university toronto .': 7, 'zemel , r .': 1, 's. hinton , g. e. .': 0, 'discovering viewpoint-invariant relationships characterize objects .': 6, 'lippmann , r. p. , moody , j. e. , touretzky , d. s. , editors , advances neural information processing systems , pages - .': 35, 'morgan kaufmann publishers .': 2}\n"
     ]
    }
   ],
   "source": [
    "sent_score = {}\n",
    "for sent in sent_token:\n",
    "    sent_score[sent] = 0  # Initialize the sentence score to 0\n",
    "    for word in sent.split():\n",
    "        if word in word_freq:\n",
    "            sent_score[sent] += word_freq[word]  # Increment the score by the word's frequency\n",
    "\n",
    "print(sent_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a25435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T11:29:20.996955Z",
     "iopub.status.busy": "2024-07-29T11:29:20.996279Z",
     "iopub.status.idle": "2024-07-29T11:29:21.008844Z",
     "shell.execute_reply": "2024-07-29T11:29:21.007510Z",
     "shell.execute_reply.started": "2024-07-29T11:29:20.996916Z"
    },
    "papermill": {
     "duration": 0.027817,
     "end_time": "2024-07-31T11:42:16.339613",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.311796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentence Scores DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0004e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:16.398745Z",
     "iopub.status.busy": "2024-07-31T11:42:16.397667Z",
     "iopub.status.idle": "2024-07-31T11:42:16.420939Z",
     "shell.execute_reply": "2024-07-31T11:42:16.419290Z"
    },
    "papermill": {
     "duration": 0.055476,
     "end_time": "2024-07-31T11:42:16.423605",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.368129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u sing neural net instantiate deformable model...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however , severe search problems associated fi...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>show using neural networks provide better star...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method demonstrated character recognition task .</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>previous work developed approach handwritten c...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>zemel , r .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>s. hinton , g. e. .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>discovering viewpoint-invariant relationships ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>lippmann , r. p. , moody , j. e. , touretzky ,...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>morgan kaufmann publishers .</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  score\n",
       "0    u sing neural net instantiate deformable model...    167\n",
       "1    however , severe search problems associated fi...     69\n",
       "2    show using neural networks provide better star...     97\n",
       "3     method demonstrated character recognition task .     31\n",
       "4    previous work developed approach handwritten c...     91\n",
       "..                                                 ...    ...\n",
       "177                                        zemel , r .      1\n",
       "178                                s. hinton , g. e. .      0\n",
       "179  discovering viewpoint-invariant relationships ...      6\n",
       "180  lippmann , r. p. , moody , j. e. , touretzky ,...     35\n",
       "181                       morgan kaufmann publishers .      2\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(sent_score.items()),columns=[\"sentence\",'score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06842b01",
   "metadata": {
    "papermill": {
     "duration": 0.027122,
     "end_time": "2024-07-31T11:42:16.478634",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.451512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Summarization depend on Sentences score\n",
    "\n",
    "\n",
    "### SentiBERT Enhancements\n",
    "- **Text Summarization**: Uses BART transformer with optimized performance.\n",
    "- **Sentiment Analysis**: Integrated with TextBlob for sentiment polarity and subjectivity scoring.\n",
    "- **Dashboard**: Real-time visualization of summarization and sentiment analysis results using Dash and Plotly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843acd99",
   "metadata": {
    "papermill": {
     "duration": 0.027054,
     "end_time": "2024-07-31T11:42:16.532856",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.505802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* You can adjust the **num_of_sent**  to specify the number of sentences you want to include in the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32bda979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:16.589876Z",
     "iopub.status.busy": "2024-07-31T11:42:16.589408Z",
     "iopub.status.idle": "2024-07-31T11:42:16.598547Z",
     "shell.execute_reply": "2024-07-31T11:42:16.597020Z"
    },
    "papermill": {
     "duration": 0.040848,
     "end_time": "2024-07-31T11:42:16.601328",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.560480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'using neural net instantiate deformable model cps model cps model cps model figure : prediction network architecture . judging weight using neural net instantiate deformable model schedule number trivial net prediction net average time required settle one model . . . deformable models digit recognition basic idea using deformable models digit recognition digit model , test image classified finding model likely generated .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "num_of_sent=3\n",
    "nn=nlargest(num_of_sent,sent_score,key=sent_score.get)\n",
    "\" \".join(nn) # to string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cfa87e",
   "metadata": {
    "papermill": {
     "duration": 0.028667,
     "end_time": "2024-07-31T11:42:16.658446",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.629779",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b417ccd9",
   "metadata": {
    "papermill": {
     "duration": 0.028618,
     "end_time": "2024-07-31T11:42:16.715731",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.687113",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Summarization using Transformers\n",
    "\n",
    "\n",
    "### SentiBERT Enhancements\n",
    "- **Text Summarization**: Uses BART transformer with optimized performance.\n",
    "- **Sentiment Analysis**: Integrated with TextBlob for sentiment polarity and subjectivity scoring.\n",
    "- **Dashboard**: Real-time visualization of summarization and sentiment analysis results using Dash and Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a922233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:16.776684Z",
     "iopub.status.busy": "2024-07-31T11:42:16.776217Z",
     "iopub.status.idle": "2024-07-31T11:42:41.949453Z",
     "shell.execute_reply": "2024-07-31T11:42:41.947729Z"
    },
    "papermill": {
     "duration": 25.207295,
     "end_time": "2024-07-31T11:42:41.953418",
     "exception": false,
     "start_time": "2024-07-31T11:42:16.746123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 11:42:21.408203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 11:42:21.408389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 11:42:21.592515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db45aadfd374a1baeeaad3899b1e717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dee642850bc4fd5ae2e74c1fb0473e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b645db22940b4ac58f7063ec16e41ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b431298435ce4cb187879b19c55d823a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fbb5a5a8384368a68183e05eb60e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f69d8092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:42.028308Z",
     "iopub.status.busy": "2024-07-31T11:42:42.027173Z",
     "iopub.status.idle": "2024-07-31T11:42:42.038188Z",
     "shell.execute_reply": "2024-07-31T11:42:42.036510Z"
    },
    "papermill": {
     "duration": 0.051663,
     "end_time": "2024-07-31T11:42:42.041452",
     "exception": false,
     "start_time": "2024-07-31T11:42:41.989789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u sing neural net instantiate deformable model abstract deformable models attractive approach recognizing nonrigid objects considerable class variability severe search problems associated fitting models data show using neural networks provide better starting points search time reduced method demonstrated character recognition task previous work developed approach handwritten character recognition based use deformable models revow obtained good performance method major problem search procedure fitting model image intensive efficient task paper demonstrate possible compile knowledge gained fitting models data obtain starting points reduce search time deformable models digit recognition basic idea using deformable models digit model test image classified finding model generated quality match model test image depends deformation model amount ink attributed noise distance remaining ink deformed model current address department computer science applied mathematics important terms assessing fit prior probability distribution instantiation parameters model penalizes distorted models imaging model characterizes probability distribution possible images given instantiated model l let image model instantiation parameters evidence model given p j ppdz first term instantiation parameters second model likelihood data given instantiated model proportional p assume prior equation correct z dimensions evaluation integral intensive possible make approximation based assumption integrand peaked maximum value case evidence approximated highest peak volume factor measures sharpness peak p taylor expanding second order shown volume factor depends determinant hessian gp taking logs equation defining edej negative log p ejit corresponding term imaging model aim search find minimum e tot edej course total energy many local character recognition task aim find global minimum using continuation method splines transforms imaging models section presents brief overview work using deformable models digit recognition fuller treatment see revow modelled b spline shape determined positions control points object based frame models control points model model generate ideal example digit control points positioned home locations deformed characters produced perturbing control points home locations home locations covariance matrix model adapted order improve performance deformation energy penalizes shape deformations affine transformations translation rotation dilation elongation shear change underlying shape object want deformation achieve giving model object based frame computing relative frame framework used many authors approximation popularized neural net community mackay using neural net instantiate deformable model data used consists binary pixel images segmented handwritten digits general imaging model problem high probability inked pixels close spline lower probabilities achieved spacing number gaussian ink generators contour found useful uniform background noise process area image able account pixels occur generators ink generators background process define mixture model using assumption data point generated given instantiated model p factors product probability density black pixel mixture model recognizing isolated digits model aim search find instantiation parameters minimize tot search starts deformations initial guess affine parameters scales model lie skew rotation small number generators large variance placed spline forming broad smooth high ink probability spline use search procedure similar expectation maximization method fitting unconstrained mixture gaussians constrained lie spline energy term affine transformation recalculated iteration search number generators increased variance decreases according predetermined annealing schedule fitting models particular image wish evaluate models explains data natural measure sum ejit edej volume factor found performance improved including additional terms obtained final fits model image measure penalizes matches beads inked pixels rotation shear elongation affine decide principled way correct weightings terms evaluation function estimated weightings data training simple postprocessing neural network inputs connected output units output units compete using softmax function guarantees form probability distribution summing predicting instantiation parameters search procedure described time consuming given many examples images corresponding instantiation parameters obtained slow method possible train neural predict instantiation parameters novel images predictions provide better starting points search time reduced schedule starts beads increasing beads steps variance decreasing scale set object based frame model unit high previous work previous work hypothesizing instantiation parameters placed broad classes correspondence based search parameter space search correspondence based search idea extract features image identify corresponding features model using sufficient correspondences model determined problem simple detectable image features many possible matches complex features require computation difficult detect shows search space possible correspondences using interpretation tree alternative approach used techniques work parameter space designed detection straight lines images extended cover number geometric shapes conic sections ballard extended approach arbitrary shapes generalized parameter space model divided cells image feature vote added parameter produced feature collecting votes image features search peaks parameter accumulator array attempt verify pose viewed crude way approximating posterior distribution p techniques used problems involving rigid models applicable digit recognition problem space method binning vote collection impractical high dimensional parameter space correspondence based approach lack identified discriminative features strengths techniques ability deal arbitrary scalings rotations translations data tolerance extraneous features required task input data segmented normalized approach use neural network predict instantiation parameters model given input image used similar method simple objects beymer constructed network maps face image parameter space spanning head rotations smile smile dimension method map images instantiation parameters use computer vision determine displacement field pixels novel image relative reference image use field input network step limits use approach images similar correspondence functions instantiating digit models using neural networks network used predict model parameters shown figure binary images normalized give greyscale images fed neural network uses standard layer architecture hidden unit computes weighted sum inputs feeds value sigmoidal nonlinearity using neural net instantiate deformable model cps model cps model model figure prediction network architecture cps stands control points output values weighted linear combination hidden unit activities output biases targets locations control points normalized image found fitting models described section network trained backpropagation minimize squared error using training images validation images digit drawn set cedar database cities states zip codes digits alphabetic characters test sets used obtained data bs test set experimentation chose network hidden units means net weights large number weights important regularize solution obtained network using complexity penalty used weight optimized validation set targets set penalty correct output layer backpropagated output units took epochs train using default conjugate gradient search method xerion simulator possible construct separate networks carry task net described intensify danger overfitting reduced giving network common pool hidden units use decides appropriate prediction net described trivial network consisted output biases trained network learns average value control point locations validation set squared error prediction net times smaller trivial net encouraging acid test compare performance elastic models settled predicted positions using shortened annealing schedule predictions good short amount settling required made available office advanced technology xerion designed implemented drew camp tony comparision initial instantiations due prediction net trivial net image notice model prediction net closer data digit models mayor affected input data example predictions nets seem prediction net puts model data feedforward predicts position control points normalized image inverting normalization process positions control points normalized image determined model corresponding image control point locations determined running part iteration search procedure experiments conducted number shortened annealing schedules data obtained settling part training data used train postprocessing net performance evaluated test set full annealing schedule stages shortened annealing schedules settling iterations final variance iteration full annealing schedule results test set shown table general trends performance obtained using prediction net trivial net annealing schedules lead better performance comparison schedules table indicates performance prediction net schedule combination similar obtained full annealing schedule factor results full schedule identical results obtained default initialization described section figure compares outputs prediction trivial nets particular example judging weight using neural net instantiate deformable model schedule number trivial net prediction net average time required settle model table errors internal test set examples different annealing schedules timing trials carried r- machine vectors activity patterns hidden units seem units specialized particular digit class run test set using schedule gave error rate similar errors obtained using full annealing box initialization comparison errors made runs shows errors common sets suggests sensible reject cases methods agree discussion prediction net used viewed interpolation scheme control point position space z predicted position control point space contribution due biases ai activity hidden unit control point position space hidden units output dimensions particular image infinite number ways make equation hold network find solutions ai vary image perturbed nets described output set instantiation parameters given model preferable able represent number guesses model instantiation parameters way train network multiple sets output parameters mixture experts architecture jacobs ai outputs interpreted mixture distribution control point position space conditioned input image approach providing information posterior distribution described p approximated using fixed set basis functions weighting depends input image i. strategies descriped predict instantiation parameters parameter space possible use neural networks hypothesize correspondences inked position spline given local window context image sufficient matches possible compute parameters model conducted preliminary experiments method indicate good performance achieved correspondence prediction task shown obtain significant speedup using prediction net schemes outlined allow multimodal predictions instantiation parameter space improve performance deserve investigation interested improving performance prediction net example outputting confidence measure used adjust length elastic models search believe using machine learning techniques neural networks help reduce amount search required fit complex models data useful many problems acknowledgements research funded apple information research centre thank rich zemel helpful discussions advanced research references ballard generalizing detect arbitrary shapes pattern recognition example based image analysis synthesis memo laboratory hands pattern theoretic study biological shapes object computer cambridge revow adaptive elastic models hand printed character recognition editors advances neural information processing systems revow combinining methods recognizing hand printed digits aleksander editors artificial neural networks elsevier science publishers hunt performance relationship statistical signal detection theory computer vision graphics image processing local experts neural computation mackay neural computation using mixtures deformable models capture variations hand printed digits editor proceedings third international workshop frontiers handwriting recognition pages combining deformable models neural networks handprinted recognition phd thesis dept computer discovering viewpoint invariant relationships characterize objects editors advances neural information processing systems pages publishers'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_text = \" \".join(tokens_1)\n",
    "(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aa96e0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T11:42:42.103650Z",
     "iopub.status.busy": "2024-07-31T11:42:42.103140Z",
     "iopub.status.idle": "2024-07-31T11:43:13.077147Z",
     "shell.execute_reply": "2024-07-31T11:43:13.075921Z"
    },
    "papermill": {
     "duration": 31.037363,
     "end_time": "2024-07-31T11:43:13.108924",
     "exception": false,
     "start_time": "2024-07-31T11:42:42.071561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u sing neural net instantiate deformable models attractive approach recognizing nonrigid objects considerable class variability severe search problems associated fitting models data show using neural networks provide better starting points search time reduced . phd thesis dept computer discovering viewpoint invariant relationships characterize objects .\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(result_text, max_length=150, min_length=30, do_sample=False)\n",
    "\n",
    "print(summary[0]['summary_text'])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 491,
     "sourceId": 9097,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 84.351808,
   "end_time": "2024-07-31T11:43:16.787913",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T11:41:52.436105",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00b1799a3c734cb3b8cb800a553519a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "10700bd0cc074fedb1699253f48efd38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "16b91b6053ae4505a5cbcee23ab0da64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1ca68bc7fe2a4f5baeb42cb1b5cdcf22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1d903e236f9444ce80031ce1e73b5dbb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff5c2afdbfe34121818572c0bc4e2389",
       "max": 791656,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3570c0b81032434983b219bad1b04fdc",
       "value": 791656
      }
     },
     "1dee642850bc4fd5ae2e74c1fb0473e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_eafcffbb86174081bf45a8d40fb36fa4",
        "IPY_MODEL_56c4bd876bd84341a130956b0f304008",
        "IPY_MODEL_5149f002582e49f98d2f410a929123f8"
       ],
       "layout": "IPY_MODEL_e0f6015913a6497a946173125e6ee210"
      }
     },
     "20f4fed2060a406686273c97eba8e75a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5126e041c45748a69676ec0dce32c4ab",
       "placeholder": "",
       "style": "IPY_MODEL_e15080803fff4b0e90d2206f85ea0b20",
       "value": "tokenizer.json:100%"
      }
     },
     "3570c0b81032434983b219bad1b04fdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d86fbf33e8849a69aed151a80ec181d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4105136f20d94e85994569d59811a37a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c4894a903bfd4e6caca8ea7b48d6c3da",
       "placeholder": "",
       "style": "IPY_MODEL_6c7d3e92efba4e1b899226506fd0fea3",
       "value": "792k/792k[00:00&lt;00:00,3.08MB/s]"
      }
     },
     "45ba321395fc4639857eb5ae494fff2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3d86fbf33e8849a69aed151a80ec181d",
       "placeholder": "",
       "style": "IPY_MODEL_9f9dffbdcd54435e98f4216eb83d6eb6",
       "value": "generation_config.json:100%"
      }
     },
     "49c13f40d96a467b95c6a7def764e193": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4db45aadfd374a1baeeaad3899b1e717": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80a690dcd48b40eb8a76862b3c0bab9c",
        "IPY_MODEL_56b1dcb93a9a426ea8a24050280d3b85",
        "IPY_MODEL_cf5e86a69b3844f997b984b8367329e6"
       ],
       "layout": "IPY_MODEL_886bc11a1ea34cf88ecc5e6b6fba6f1a"
      }
     },
     "5126e041c45748a69676ec0dce32c4ab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5149f002582e49f98d2f410a929123f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5e97dcb6d90345da943b849d9778cdc7",
       "placeholder": "",
       "style": "IPY_MODEL_b60667def89147e7887486ab65a77e41",
       "value": "892M/892M[00:03&lt;00:00,275MB/s]"
      }
     },
     "56b1dcb93a9a426ea8a24050280d3b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e99d6c0f363346a89a98091aa0c451a7",
       "max": 1208,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ca68bc7fe2a4f5baeb42cb1b5cdcf22",
       "value": 1208
      }
     },
     "56c4bd876bd84341a130956b0f304008": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_10700bd0cc074fedb1699253f48efd38",
       "max": 891646390,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_16b91b6053ae4505a5cbcee23ab0da64",
       "value": 891646390
      }
     },
     "5789dcb42e9a4a1e9f35f61d7b416de8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e97dcb6d90345da943b849d9778cdc7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "616e32001ed6492abf669d86e0a71107": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_af93ec710bc24904a6879507731c9aee",
       "max": 147,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b24afda5f39c4d27b04e3c012629b8e5",
       "value": 147
      }
     },
     "6c7d3e92efba4e1b899226506fd0fea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7611302795b34d609e4370500bcd0dac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b88590eca1ef4d36a499e214a774a01a",
       "placeholder": "",
       "style": "IPY_MODEL_aa6393a6425e41b2af4d721667154697",
       "value": "1.39M/1.39M[00:00&lt;00:00,4.28MB/s]"
      }
     },
     "7c5ebd0a80bd4c9fb46bd5ff917c5082": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80a690dcd48b40eb8a76862b3c0bab9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5789dcb42e9a4a1e9f35f61d7b416de8",
       "placeholder": "",
       "style": "IPY_MODEL_00b1799a3c734cb3b8cb800a553519a6",
       "value": "config.json:100%"
      }
     },
     "886bc11a1ea34cf88ecc5e6b6fba6f1a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88fbb5a5a8384368a68183e05eb60e27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_20f4fed2060a406686273c97eba8e75a",
        "IPY_MODEL_a8f9ab4ccc594171b3fe1ff06d93998c",
        "IPY_MODEL_7611302795b34d609e4370500bcd0dac"
       ],
       "layout": "IPY_MODEL_ffec99fbc2124aa1ad935f916dcf6ff9"
      }
     },
     "921ac6772f6a428eae13b8a0cd1f5b73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9431543dd80b4249b5d3ac13ef3f9809": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94d30d51c5d24c3cbef7192ccc965eff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9bbf23ac6d7c419bb046754bc352c85b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9f9dffbdcd54435e98f4216eb83d6eb6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a8f9ab4ccc594171b3fe1ff06d93998c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_921ac6772f6a428eae13b8a0cd1f5b73",
       "max": 1389353,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fedc4a7b9905449abf95ab4a108002bc",
       "value": 1389353
      }
     },
     "aa6393a6425e41b2af4d721667154697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "af51b29348f7437e8339bbdc7c52420d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d890ce686bce47199f33e14e62d4d66d",
       "placeholder": "",
       "style": "IPY_MODEL_94d30d51c5d24c3cbef7192ccc965eff",
       "value": "spiece.model:100%"
      }
     },
     "af93ec710bc24904a6879507731c9aee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b24afda5f39c4d27b04e3c012629b8e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b431298435ce4cb187879b19c55d823a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_af51b29348f7437e8339bbdc7c52420d",
        "IPY_MODEL_1d903e236f9444ce80031ce1e73b5dbb",
        "IPY_MODEL_4105136f20d94e85994569d59811a37a"
       ],
       "layout": "IPY_MODEL_49c13f40d96a467b95c6a7def764e193"
      }
     },
     "b60667def89147e7887486ab65a77e41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b645db22940b4ac58f7063ec16e41ec7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_45ba321395fc4639857eb5ae494fff2b",
        "IPY_MODEL_616e32001ed6492abf669d86e0a71107",
        "IPY_MODEL_ec17bba6e559463e821dd07ab164fe88"
       ],
       "layout": "IPY_MODEL_f7527c65a5b64435ba3cd5ca76b56032"
      }
     },
     "b88590eca1ef4d36a499e214a774a01a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4894a903bfd4e6caca8ea7b48d6c3da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf5e86a69b3844f997b984b8367329e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9431543dd80b4249b5d3ac13ef3f9809",
       "placeholder": "",
       "style": "IPY_MODEL_d081172f174d4bb281c8bd3f71bcedeb",
       "value": "1.21k/1.21k[00:00&lt;00:00,74.2kB/s]"
      }
     },
     "d081172f174d4bb281c8bd3f71bcedeb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d78221e2fc9c46438d4c6135fbcdcdda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d890ce686bce47199f33e14e62d4d66d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0f6015913a6497a946173125e6ee210": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e15080803fff4b0e90d2206f85ea0b20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e70dd78e8ca64273b04d622696b22437": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e99d6c0f363346a89a98091aa0c451a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eafcffbb86174081bf45a8d40fb36fa4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e70dd78e8ca64273b04d622696b22437",
       "placeholder": "",
       "style": "IPY_MODEL_d78221e2fc9c46438d4c6135fbcdcdda",
       "value": "model.safetensors:100%"
      }
     },
     "ec17bba6e559463e821dd07ab164fe88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c5ebd0a80bd4c9fb46bd5ff917c5082",
       "placeholder": "",
       "style": "IPY_MODEL_9bbf23ac6d7c419bb046754bc352c85b",
       "value": "147/147[00:00&lt;00:00,9.80kB/s]"
      }
     },
     "f7527c65a5b64435ba3cd5ca76b56032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fedc4a7b9905449abf95ab4a108002bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ff5c2afdbfe34121818572c0bc4e2389": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffec99fbc2124aa1ad935f916dcf6ff9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
